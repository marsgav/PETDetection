{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marsgav/PETDetection/blob/main/Euph_Detection_on_Euph_Corpus_4_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7db7b57-593f-402b-9e89-bd9b91b2ebfc",
      "metadata": {
        "id": "f7db7b57-593f-402b-9e89-bd9b91b2ebfc"
      },
      "source": [
        "## Testing on euph corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a826d2-feed-40fa-82bc-b522d3378c67",
      "metadata": {
        "id": "74a826d2-feed-40fa-82bc-b522d3378c67"
      },
      "source": [
        "#### Load and preprocess euph sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "139ed7ad-2115-4b72-b97a-f1c37bd661c6",
      "metadata": {
        "id": "139ed7ad-2115-4b72-b97a-f1c37bd661c6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "euph_corpus = pd.read_csv('Euphemism_Corpus_2-24.csv', index_col=0, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bf54fb6-1ff6-4b92-932b-a55b2f50d43e",
      "metadata": {
        "id": "2bf54fb6-1ff6-4b92-932b-a55b2f50d43e"
      },
      "outputs": [],
      "source": [
        "def preprocess(s):\n",
        "    s = s.strip()\n",
        "    s = re.sub(r'(##\\d*\\W)|<\\w>|,|;|:|--|\\(|\\)|#|%|\\\\|\\/|\\.|\\*|\\+|@', '', s)\n",
        "    s = re.sub(r'\\s\\s+', ' ', s)\n",
        "    s = s.lower()\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346edc29-5cd1-4af3-bfa0-22dc8c95dcf5",
      "metadata": {
        "id": "346edc29-5cd1-4af3-bfa0-22dc8c95dcf5"
      },
      "outputs": [],
      "source": [
        "# preprocess sentences\n",
        "for i, row in euph_corpus.iterrows():\n",
        "    text = euph_corpus.loc[i, 'sentence']\n",
        "    euph_corpus.loc[i, 'sentence'] = preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeef0f1e-1224-4a47-88ea-7524a33eb350",
      "metadata": {
        "id": "aeef0f1e-1224-4a47-88ea-7524a33eb350"
      },
      "outputs": [],
      "source": [
        "# phrasify the sentences\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "\n",
        "bigram_phraser = Phraser.load('bigram_phraser_5')\n",
        "trigram_phraser = Phraser.load('trigram_phraser_5')\n",
        "euph_corpus['phrases'] = \"\"\n",
        "data = [] # holds phrased input sentences to update wv model with\n",
        "\n",
        "for i, row in euph_corpus.iterrows():\n",
        "    text = euph_corpus.loc[i, 'sentence']\n",
        "    euph_corpus.at[i, 'phrases'] = bigram_phraser[text.split()] # use phraser to detect phrases in text\n",
        "    euph_corpus.at[i, 'phrases'] = trigram_phraser[euph_corpus.loc[i, 'phrases']]\n",
        "    data.append(euph_corpus.loc[i, 'phrases'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26467c31-7785-47b9-9e21-694bcbaff4d4",
      "metadata": {
        "id": "26467c31-7785-47b9-9e21-694bcbaff4d4"
      },
      "outputs": [],
      "source": [
        "# confirm the phraser is still working\n",
        "# trigram_phraser[['are', 'we', 'talking', 'the', 'merits', \"of'\", 'enhanced_interrogation', 'techniques', 'or', 'the', 'definition', 'of', 'torture']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "908de415-37ea-490d-bc83-c04c4b67c11e",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "908de415-37ea-490d-bc83-c04c4b67c11e",
        "outputId": "034ac18e-17ea-46df-b2a8-8d0ae2e7e07e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"i'm\", 'in', 'the', 'same', 'situation', 'disabled', 'chronic_pain', 'artist', 'no', 'visible', 'disability', 'even', 'when', \"i'm\", 'in', 'my', 'chair', 'and', 'nobody_understands', 'that', 'it', 'takes', 'us', 'longer', 'to', 'do', 'everything']\n",
            "i'm in the same situation disabled chronic_pain artist no visible disability even when i'm in my chair and nobody_understands that it takes us longer to do everything\n",
            "['whether', 'they', 'take', 'the', 'form', 'of', 'the', \"neurologist's\", 'multimodal', 'sensory', 'integrations', 'or', 'the', 'alternative', 'sense', 'organs', 'described', 'by', 'disabled', 'writers', 'and', 'performers', 'these', 're-organized', 'sensations', 'suggest', 'a', 'need', 'for', 'interdisciplinary', 'anti-disciplinary']\n",
            "whether they take the form of the neurologist's multimodal sensory integrations or the alternative sense organs described by disabled writers and performers these re-organized sensations suggest a need for interdisciplinary anti-disciplinary\n",
            "['the', 'proud', 'smile', 'of', 'a', 'first-grader', 'who', 'suddenly', 'gets', 'a', 'math', 'problem', 'the', 'beaming', 'face', 'of', 'a', 'shut-in', 'as', 'she', 'receives', 'a', 'long-awaited', 'volunteer', 'visitor', 'the', 'opportunity', 'for', 'a', 'disabled_veteran', 'to', 'attend', 'a', 'redskins', 'game', 'escaping', 'the', 'hard', 'realities', 'of', 'his', 'hospital', 'stay', 'and', 'the', 'relief', 'etched', 'on', 'the', 'faces', 'of', 'children', 'as', 'they', 'enjoy', 'a', 'shower', 'and', 'warm', 'meal', 'in', 'a', 'red_cross', 'facility', 'following', 'a', 'disaster']\n",
            "the proud smile of a first-grader who suddenly gets a math problem the beaming face of a shut-in as she receives a long-awaited volunteer visitor the opportunity for a disabled_veteran to attend a redskins game escaping the hard realities of his hospital stay and the relief etched on the faces of children as they enjoy a shower and warm meal in a red_cross facility following a disaster\n",
            "['it', 'was', 'a', 'crime', 'against', 'the', 'disabled', 'and', 'she', 'is', 'out', 'on', 'the', 'streets', 'cured']\n",
            "it was a crime against the disabled and she is out on the streets cured\n",
            "['many', 'of', 'the', 'elderly_or_disabled', \"don't\", 'want', 'a', 'fancy', 'phone', 'just', 'a', 'way', 'to', 'call', 'for', 'help', 'in', 'case', 'of', 'trouble']\n",
            "many of the elderly_or_disabled don't want a fancy phone just a way to call for help in case of trouble\n",
            "['i', 'am', 'a', '40', 'year_old', 'disabled_vet', 'who', 'has', 'returned', 'to', 'school', 'for', 'my', 'political_science', 'degree']\n",
            "i am a 40 year_old disabled_vet who has returned to school for my political_science degree\n",
            "['the', 'money', 'i', 'got', 'from', 'it', 'was', 'donated', 'to', 'fund_raising', 'for', 'disabled', 'kids']\n",
            "the money i got from it was donated to fund_raising for disabled kids\n",
            "['he', 'used', 'the', 'information', 'of', 'a', 'deceased', 'and', 'developmentally_disabled', 'individual', 'from', 'a', 'nassau_county', 'group', 'home', 'to', 'obtain', 'a', 'fraudulent', 'debit_card', 'and', 'was', 'also', 'arrested', 'for', 'credit_card', 'fraud', 'near', 'atlanta_georgia']\n",
            "he used the information of a deceased and developmentally_disabled individual from a nassau_county group home to obtain a fraudulent debit_card and was also arrested for credit_card fraud near atlanta_georgia\n",
            "['when', 'during', 'the', 'speech', 'he', 'belted_out', 'all', 'americans', 'male_or_female', 'young', 'and', 'not', 'so', 'young', 'black', 'or', 'white', 'or', 'hispanic_or_asian', 'gay', 'or', 'straight', 'disabled', 'and', 'not', 'disabled', 'i', 'thought', 'it', 'was', 'impossible']\n",
            "when during the speech he belted_out all americans male_or_female young and not so young black or white or hispanic_or_asian gay or straight disabled and not disabled i thought it was impossible\n",
            "['when', 'during', 'the', 'speech', 'he', 'belted_out', 'all', 'americans', 'male_or_female', 'young', 'and', 'not', 'so', 'young', 'black', 'or', 'white', 'and', 'not', 'disabled', 'i', 'thought', 'it', 'was', 'impossible']\n",
            "when during the speech he belted_out all americans male_or_female young and not so young black or white and not disabled i thought it was impossible\n",
            "['this', 'of', 'course', 'is', 'all', 'dependent', 'on', 'never', 'missing', 'a', 'paycheck', 'or', 'becoming', 'to', 'disabled', 'to', 'do', 'my', 'physically_demanding', 'job']\n",
            "this of course is all dependent on never missing a paycheck or becoming to disabled to do my physically_demanding job\n",
            "['this', 'site', 'is', 'terrific', 'but', 'i', 'work', 'with', 'developmentally_disabled_adults', 'with', 'the', 'interests', 'and', 'attention_span', 'of', '4-5_year_olds']\n",
            "this site is terrific but i work with developmentally_disabled_adults with the interests and attention_span of 4-5_year_olds\n",
            "['she', 'sits', 'back', 'and', 'watches', 'as', 'their', 'disabled', 'teenage_son', 'idolizes', \"walt's\", 'coolness', 'and', 'simultaneously', 'result', 'of', 'her', 'oft-understandable', 'protectiveness']\n",
            "she sits back and watches as their disabled teenage_son idolizes walt's coolness and simultaneously result of her oft-understandable protectiveness\n",
            "['can', 'it', 'be', 'disabled']\n",
            "can it be disabled\n",
            "['i', 'am', 'a', 'disabled', 'vietnam_veteran', 'who', 'served_honorably']\n",
            "i am a disabled vietnam_veteran who served_honorably\n",
            "['i', 'liked', 'langevin', 'too', 'bc', \"it's\", 'not', 'easy', 'to', 'be', 'disabled', 'as', 'he', 'is', 'and', 'achieve', '&', 'work', 'long', 'hours', 'in', 'politics', 'world', 'or', 'our', 'cruel', 'society']\n",
            "i liked langevin too bc it's not easy to be disabled as he is and achieve & work long hours in politics world or our cruel society\n",
            "[\"you're\", 'half', 'in', 'love', 'with', 'skyler', \"walt's\", 'beautiful', 'resourceful', 'wife', 'anna_gunn', 'and', 'handsome', 'disabled', 'son', 'rj', 'mitte', 'you', 'have', 'an', \"insider's\", 'knowledge', 'of', 'his', 'extended_family', 'including', 'his', 'blustery', 'drug_enforcement', 'administration', 'brother-in-law', 'hank', 'dean', 'norris', 'and', \"skyler's\", 'ditzy', 'kleptomaniac', 'sister', 'marie', 'betsy_brandt']\n",
            "you're half in love with skyler walt's beautiful resourceful wife anna_gunn and handsome disabled son rj mitte you have an insider's knowledge of his extended_family including his blustery drug_enforcement administration brother-in-law hank dean norris and skyler's ditzy kleptomaniac sister marie betsy_brandt\n",
            "['i', 'do', 'have', 'a', \"driver's\", 'license', 'but', 'there', 'are', 'many', 'elderly_and_disabled', 'people', 'living', 'in', 'my', 'building', 'who', 'do', 'not']\n",
            "i do have a driver's license but there are many elderly_and_disabled people living in my building who do not\n",
            "['you', 'are', 'no_matter', 'what', 'the', 'licensing_boards', 'say', 'career', 'working', 'with', 'the', 'disabled', 'and', 'recovering', 'elderly', 'among', 'others']\n",
            "you are no_matter what the licensing_boards say career working with the disabled and recovering elderly among others\n",
            "['got', 'all', 'the', 'working', 'people', 'and', 'stay-home', 'moms', 'who', 'use', 'it', 'to', 'go', 'to', 'a', 'council_meeting', 'and', 'tell', 'them', 'how', 'much', 'it', 'would', 'cost', 'them', 'if', 'all', 'the', 'health_benefits', 'daycare', 'and', 'disease-prevention', 'factors', 'would', 'fall', 'to', 'the', 'city', 'if', 'they', 'offed', 'the', 'pool', 'as', 'well', 'as', 'how', 'many', 'tax_dollars', 'would', 'disappear', 'if', 'some', 'of', 'them', 'became', 'so', 'disabled', 'they', 'could', 'no_longer', 'work']\n",
            "got all the working people and stay-home moms who use it to go to a council_meeting and tell them how much it would cost them if all the health_benefits daycare and disease-prevention factors would fall to the city if they offed the pool as well as how many tax_dollars would disappear if some of them became so disabled they could no_longer work\n",
            "['if', 'the', 'judges', 'decision', 'will', 'state', 'the', 'failure', 'of', 'the', 'prior_consent', 'or', 'the', 'unlawful', 'dissemination', 'of', 'the', 'disabled', 'students', 'data', 'both', 'it', 'is', 'actually', 'forbidden', 'in', 'fact', 'for', 'natural', 'persons', 'to', 'disseminate', 'other', 'peoples', 'data', 'without', 'the', 'prior_consent']\n",
            "if the judges decision will state the failure of the prior_consent or the unlawful dissemination of the disabled students data both it is actually forbidden in fact for natural persons to disseminate other peoples data without the prior_consent\n",
            "['i', \"couldn't\", 'help', 'but', 'feel', 'like', 'i', 'was', 'in', 'a', 'school', 'for', 'the', 'mentally_disabled', 'for', 'most', 'of', 'my', 'public', 'school', 'experience']\n",
            "i couldn't help but feel like i was in a school for the mentally_disabled for most of my public school experience\n",
            "['you', 'can', 'argue', 'that', 'the', 'government', 'ie', 'taxpayers', 'should', 'pay', 'for', 'the', 'uninsured', 'sick', 'and', 'disabled', 'but', 'keep_in_mind', 'that', \"you're\", 'subsidizing', 'irresponsibility']\n",
            "you can argue that the government ie taxpayers should pay for the uninsured sick and disabled but keep_in_mind that you're subsidizing irresponsibility\n",
            "['as', 'someone', 'who', 'has', 'several', 'family_members', 'disabled', 'and', 'martryed', 'since', 'the', \"emperior's\", 'era', 'it', 'makes', 'me', 'sick', 'to', 'my', 'stomach', 'to', 'find', 'out', 'that', 'the', 'final', 'beneficiary', 'of', 'the', 'bitter', '30_years', 'struggles', 'are', 'only', 'a', 'few', 'bunch', 'of', 'tplf', 'elites', 'as', 'supposed', 'to', 'all', 'the', 'ethio-eritrean', 'masses', 'equally']\n",
            "as someone who has several family_members disabled and martryed since the emperior's era it makes me sick to my stomach to find out that the final beneficiary of the bitter 30_years struggles are only a few bunch of tplf elites as supposed to all the ethio-eritrean masses equally\n",
            "[\"you'll\", 'see', 'what', 'daily', 'life', 'was', 'like', 'for', 'workers', 'the', 'poor', 'the', 'elderly', 'the', 'sick', 'the', 'disabled', 'refugees', 'women', 'children', 'slaves', 'and', 'soldiers']\n",
            "you'll see what daily life was like for workers the poor the elderly the sick the disabled refugees women children slaves and soldiers\n",
            "['these', 'things', 'are', 'all', 'true', 'of', 'angels', 'and', 'humans', 'who', 'have', 'the', 'necessary', 'mental', 'ability', 'i', 'say', 'necessary', 'because', 'some', 'human', 'persons', 'babies', 'and', 'the', 'mentally_disabled', 'lack', 'the', 'necessary', 'mental', 'ability', 'to', 'sin']\n",
            "these things are all true of angels and humans who have the necessary mental ability i say necessary because some human persons babies and the mentally_disabled lack the necessary mental ability to sin\n",
            "['there', 'could', 'be', 'an', 'argument', 'made', 'for', 'covering', 'people', 'who', 'truly', \"can't\", 'afford', 'it', 'ie', 'extremely', 'disabled', 'from', 'birth']\n",
            "there could be an argument made for covering people who truly can't afford it ie extremely disabled from birth\n",
            "['i', 'paid', 'those', 'premiums', 'for', 'twenty', 'one', 'years', 'until', 'an', 'unrelated', 'surgery', 'disabled', 'me', 'making', 'me', 'eligible_for_medicare', '&', 'disability', 'at', '63', 'years_old']\n",
            "i paid those premiums for twenty one years until an unrelated surgery disabled me making me eligible_for_medicare & disability at 63 years_old\n",
            "['ivan_nova', 'yankees', \"nova's\", 'frustating', 'sophomore_season', 'took', 'a', 'turn', 'for', 'the', 'worse', 'last_week', 'when', 'he', 'went', 'on', 'the', '15-day_disabled_list', 'with', 'rotator_cuff', 'inflammation']\n",
            "ivan_nova yankees nova's frustating sophomore_season took a turn for the worse last_week when he went on the 15-day_disabled_list with rotator_cuff inflammation\n",
            "['during', 'the', 'thrawn_campaign', 'she', 'flew', 'a', 'z-95_headhunter', 'and', 'flew', 'at', 'the', 'battle', 'for', 'the', 'katana_fleet', 'though', 'she', 'was', 'disabled', 'by', 'an', 'ion_cannon', '30', 'during', 'the', 'first', 'corellian_insurrection', 'jade_skywalker', 'piloted', 'her', 'ship', 'the', \"jade's\", 'fire', 'and', 'used', 'it', 'in', 'several', 'different', 'instances']\n",
            "during the thrawn_campaign she flew a z-95_headhunter and flew at the battle for the katana_fleet though she was disabled by an ion_cannon 30 during the first corellian_insurrection jade_skywalker piloted her ship the jade's fire and used it in several different instances\n",
            "['these', 'features', 'may', 'be', 'disabled', 'or', 'only', 'available', 'to', 'administrators', 'who', 'service', 'the', 'equipment', 'but', 'in', 'any', 'event', 'the', 'tsa', 'problems']\n",
            "these features may be disabled or only available to administrators who service the equipment but in any event the tsa problems\n",
            "['i', 'understand', 'that', 'team', 'obama', 'has', 'resorted', 'to', 'harvesting', 'the', 'votes', 'of', 'the', 'mentally_disabled', 'in', 'nc']\n",
            "i understand that team obama has resorted to harvesting the votes of the mentally_disabled in nc\n",
            "['well', 'i', \"don't\", 'think', 'that', 'a', 'low', 'self-regard', 'is', 'always', 'a', 'good', 'thing', 'but', 'it', \"doesn't\", 'mean', 'that', 'a', 'writer', 'is', 'disabled', 'either']\n",
            "well i don't think that a low self-regard is always a good thing but it doesn't mean that a writer is disabled either\n",
            "['the', 'eosinfo', 'website', 'says', 'that', 'it', 'is', 'not', 'compatible', 'with', 'the', 'canon_eos', '500d', 'which', 'also', 'should', 'be', 'true', 'as', 'canon', 'has', 'disabled', 'the', 'shutter_count', 'on', '500d', 'and', 'camerashuttercount']\n",
            "the eosinfo website says that it is not compatible with the canon_eos 500d which also should be true as canon has disabled the shutter_count on 500d and camerashuttercount\n",
            "['the', 'main', 'firefox', 'buttons', 'are', 'actually', 'one', 'big', 'file', 'that', 'contains', 'all', 'the', 'buttons', 'their', 'rollover', 'pressed', 'and', 'disabled', 'states', 'too']\n",
            "the main firefox buttons are actually one big file that contains all the buttons their rollover pressed and disabled states too\n",
            "['manning', 'went', 'on', 'the', 'disabled_list', 'and', 'was', 'out', 'until', 'september']\n",
            "manning went on the disabled_list and was out until september\n",
            "['this', 'figure', \"doesn't\", 'take', 'into_account', 'ongoing', 'losses', 'to', 'crippled', 'businesses', 'the', 'fishing_industry', 'for', 'instance', 'or', 'the', 'chilling_effects', 'of', 'a', 'disabled', 'transportation', 'system']\n",
            "this figure doesn't take into_account ongoing losses to crippled businesses the fishing_industry for instance or the chilling_effects of a disabled transportation system\n",
            "['as', 'the', 'previous', 'case', 'shows', 'the', 'frontal_lobes_of_the_brain', 'play', 'an', 'important', 'role', 'in', 'initiating', 'behavior', 'and', 'this', 'function', 'can', 'be', 'disabled', 'if', 'they', 'are', 'damaged']\n",
            "as the previous case shows the frontal_lobes_of_the_brain play an important role in initiating behavior and this function can be disabled if they are damaged\n",
            "['pavano', 'tried', 'to', 'pitch', 'through', 'a', 'shoulder_injury', 'with', 'disastrous_results', 'spent', 'the', 'final', 'four_months', 'on', 'the', 'disabled_list', 'and', 'took', 'some', 'veiled', 'shots', 'at', 'the', \"twins'\", 'medical_staff', 'on', 'his', 'way', 'out', 'the', 'door']\n",
            "pavano tried to pitch through a shoulder_injury with disastrous_results spent the final four_months on the disabled_list and took some veiled shots at the twins' medical_staff on his way out the door\n",
            "['when', 'this', 'function', 'is', 'disabled', 'by', 'brain_damage', 'the', 'result', 'is', \"capgras'\", 'syndrome', 'described', 'in', 'part', '2', 'of', 'this', 'essay']\n",
            "when this function is disabled by brain_damage the result is capgras' syndrome described in part 2 of this essay\n",
            "['security', 'system', 'was', 'efficiently', 'disabled']\n",
            "security system was efficiently disabled\n",
            "['who', 'decides', 'whether', 'or', 'not', 'i', 'am', 'disabled']\n",
            "who decides whether or not i am disabled\n",
            "['the', 'firewall', 'and', 'av', 'are', 'disabled']\n",
            "the firewall and av are disabled\n",
            "['why', \"couldn't\", 'they', 'just', 'talk', 'and', 'indeed', 'if', 'the', 'doctrine', 'of', 'the', 'soul', 'were', 'true-if', 'we', 'all', 'had', 'a', 'supernatural', 'ghost', 'in', 'our', 'heads', 'unaffected', 'by', 'physical', 'brain_damage', 'that', 'directs', 'our', 'actions-this', 'would', 'be', 'a', 'valid', 'and', 'again', 'that', 'our', 'consciousness', 'and', 'its', 'attendant', 'abilities', 'are', 'unified', 'with', 'the', 'brain', 'and', 'can', 'be', 'disabled', 'by', 'damage', 'to', 'it']\n",
            "why couldn't they just talk and indeed if the doctrine of the soul were true-if we all had a supernatural ghost in our heads unaffected by physical brain_damage that directs our actions-this would be a valid and again that our consciousness and its attendant abilities are unified with the brain and can be disabled by damage to it\n",
            "['disabled', 'and', 'able-bodied', 'sports', 'do', 'not', 'need', 'to', 'be', 'separate', 'and', 'that', 'we', 'can', 'introduce', 'sports', 'that', 'allow', 'a', 'much', 'broader', 'section', 'of', 'the', 'population', 'to', 'participate', 'together', 'observed', 'colin', 'mcswiggen', 'who', 'along', 'with', 'jeffrey', 'gough', 'and', 'juhye', 'lee', 'developed', 'the', 'device', 'to', 'demonstrate', 'how', 'people', 'living', 'with', 'quadriplegia', 'could', 'compete', 'with', 'able-bodied', 'people', 'in', 'clay_pigeon', 'shooting']\n",
            "disabled and able-bodied sports do not need to be separate and that we can introduce sports that allow a much broader section of the population to participate together observed colin mcswiggen who along with jeffrey gough and juhye lee developed the device to demonstrate how people living with quadriplegia could compete with able-bodied people in clay_pigeon shooting\n",
            "['when', 'using', 'this', 'plugin', 'your', 'page_layout', 'will', 'be', 'consistent', 'even', 'if', 'javascript', 'has', 'been', 'disabled']\n",
            "when using this plugin your page_layout will be consistent even if javascript has been disabled\n",
            "['stop_drinking_the_kool', 'aid', 'and', 'learn', 'how', 'the', 'earths', 'temperatures', 'are', 'controlled', 'in', 'the', 'book', 'pyramid', 'gravity', 'force', 'available', 'on', 'amazon', 'find', 'out', 'how', 'mans', 'penitration', 'in', 'cheops', 'the', 'great_pyramid_of_giza', 'disabled', 'the', 'great_pyramid_of_giza', 'which', 'controlled', 'the', 'hawaiian_island', 'vocanic', 'activity']\n",
            "stop_drinking_the_kool aid and learn how the earths temperatures are controlled in the book pyramid gravity force available on amazon find out how mans penitration in cheops the great_pyramid_of_giza disabled the great_pyramid_of_giza which controlled the hawaiian_island vocanic activity\n",
            "['if', 'auto', 'root', 'update', 'is', 'disabled', 'no', 'attempt', 'to', 'retrieve', 'the', 'root', 'is', 'made']\n",
            "if auto root update is disabled no attempt to retrieve the root is made\n",
            "['once', 'quee', 'and', 'sebatyne', 'disabled', 'the', 'ship', 'and', 'released', 'the', 'prisoners', 'jade_skywalker', 'brought', 'them', 'into', 'the', \"dreadnaught's\", 'hangar_bay', 'with', 'the', \"shadow'\", 's', 'tractor_beam', 'and', 'retrieved', 'the', 'two', 'females']\n",
            "once quee and sebatyne disabled the ship and released the prisoners jade_skywalker brought them into the dreadnaught's hangar_bay with the shadow' s tractor_beam and retrieved the two females\n",
            "['working', 'copies', 'can', 'be', 'stored', 'on', 'nfs', 'one', 'common', 'scenario', 'is', 'when', 'your', 'home', 'directory', 'is', 'on', 'a', 'to', 'the', 'volume', 'of', 'renames', 'used', 'internally', 'in', 'subversion', 'when', 'checking', 'out', 'files', 'some', 'users', 'have', 'reported', \"that'\", 'subtree', \"checking'\", 'should', 'be', 'disabled', \"it's\", 'enabled_by_default']\n",
            "working copies can be stored on nfs one common scenario is when your home directory is on a to the volume of renames used internally in subversion when checking out files some users have reported that' subtree checking' should be disabled it's enabled_by_default\n",
            "['in', 'a', 'few_minutes', 'two', 'of', 'the', 'federal', 'boats', 'the', 'sachem', 'and', 'the', 'clifton', 'were', 'disabled', 'and', 'the', 'others', 'left', 'the', 'harbor', 'quickly', 'to', 'escape', 'a', 'similar', 'fate']\n",
            "in a few_minutes two of the federal boats the sachem and the clifton were disabled and the others left the harbor quickly to escape a similar fate\n",
            "['implementations', 'that', 'do', 'not', 'support', 'scripting', 'or', 'which', 'have', 'their', 'scripting', 'features', 'disabled', 'entirely', 'are', 'exempt', 'from', 'supporting', 'the', 'events', 'and', 'dom_interfaces', 'mentioned', 'in', 'this', 'specification']\n",
            "implementations that do not support scripting or which have their scripting features disabled entirely are exempt from supporting the events and dom_interfaces mentioned in this specification\n",
            "['the', 'morning', 'sun', 'heating', 'the', 'hydrogen', 'forced', 'of', 'the', 'crew', 'disabled', 'by', 'oxygen_deprivation', 'it', 'was', 'a', 'struggle', 'to', 'bring', 'her', 'under', 'almost', 'partial', 'control']\n",
            "the morning sun heating the hydrogen forced of the crew disabled by oxygen_deprivation it was a struggle to bring her under almost partial control\n",
            "['their', 'highest-paid_player', 'just', 'returned', 'from', 'a', 'three-month_stint', 'on', 'the', 'disabled_list', 'and', 'already', 'had', 'to', 'miss', 'a', 'game', 'because', 'his', 'legs', 'were', 'tired']\n",
            "their highest-paid_player just returned from a three-month_stint on the disabled_list and already had to miss a game because his legs were tired\n",
            "['actually', 'no', 'it', \"can't\", 'because', 'after', 'bios', 'reset', 'you', 'have', 'control', 'over', 'boot', 'device', 'order', 'because', 'console', 'redirection', 'will', 'be', 'disabled']\n",
            "actually no it can't because after bios reset you have control over boot device order because console redirection will be disabled\n",
            "['a', 'guard', 'leaving', 'after', 'at', 'least', 'nine_months', 'of', 'service', 'is', 'entitled', 'to', 'wear', 'the', 'javascript', 'is', 'currently', 'disabled']\n",
            "a guard leaving after at least nine_months of service is entitled to wear the javascript is currently disabled\n",
            "['for', 'example', 'setting', 'the', 'disabled_attribute', 'to', 'the', 'value', 'false', 'is', 'disallowed', 'because', 'despite', 'the', 'appearance', 'of', 'meaning', 'that', 'the', 'element', 'is', 'enabled', 'it', 'in', 'fact', 'means', 'that', 'the', 'element', 'is', 'disabled', 'what', 'matters', 'for', 'implementations', 'is', 'the', 'presence', 'of', 'the', 'attribute', 'not', 'its', 'value']\n",
            "for example setting the disabled_attribute to the value false is disallowed because despite the appearance of meaning that the element is enabled it in fact means that the element is disabled what matters for implementations is the presence of the attribute not its value\n",
            "['by', 'then', 'they', 'may', 'be', 'unable', 'to', 'steer', 'any', 'heading', 'but', 'in', 'the', 'trough', 'of', 'the', 'sea', 'or', 'may', 'have', 'their', 'steering', 'control', 'lighting', 'communications', 'and', 'main', 'propulsion', 'disabled', 'or', 'may', 'be', 'helpless', 'to', 'secure', 'things', 'on', 'deck', 'or', 'to', 'jettison', 'topside', 'weights']\n",
            "by then they may be unable to steer any heading but in the trough of the sea or may have their steering control lighting communications and main propulsion disabled or may be helpless to secure things on deck or to jettison topside weights\n",
            "['conformance_checkers', 'must', 'check', 'that', 'the', 'input_document_conforms', 'when', 'parsed', 'without', 'a', 'browsing_context', 'meaning', 'that', 'no', 'scripts', 'are', 'run', 'and', 'that', 'the', \"parser's\", 'scripting', 'flag', 'is', 'disabled', 'and', 'should', 'also', 'check', 'that', 'the', 'input_document_conforms', 'when', 'parsed', 'with', 'a', 'browsing_context', 'in', 'which', 'scripts', 'execute', 'and', 'that', 'the', 'scripts', 'never', 'cause', 'non-conforming', 'states', 'to', 'occur', 'other', 'than', 'transiently', 'during', 'script_execution', 'itself']\n",
            "conformance_checkers must check that the input_document_conforms when parsed without a browsing_context meaning that no scripts are run and that the parser's scripting flag is disabled and should also check that the input_document_conforms when parsed with a browsing_context in which scripts execute and that the scripts never cause non-conforming states to occur other than transiently during script_execution itself\n",
            "['so', 'i', 'went', 'on', 'settings', 'disabled', 'wifi', 'then', 'cellular', 'and', 'disabled', 'cellular_data']\n",
            "so i went on settings disabled wifi then cellular and disabled cellular_data\n"
          ]
        }
      ],
      "source": [
        "# temporary - seeing results for a particular keyword\n",
        "selection = euph_corpus[euph_corpus['keyword'] == 'disabled']\n",
        "for i, row in selection.iterrows():\n",
        "    print(selection.loc[i, 'phrases'])\n",
        "    print(' '.join(selection.loc[i, 'phrases']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e543dfa-0ea0-4c08-9c34-ef8e1ccdaa65",
      "metadata": {
        "tags": [],
        "id": "6e543dfa-0ea0-4c08-9c34-ef8e1ccdaa65"
      },
      "source": [
        "#### Define topic similarity function, topic list and stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f09267-a883-4fc2-83b8-ef3ad151c679",
      "metadata": {
        "id": "35f09267-a883-4fc2-83b8-ef3ad151c679"
      },
      "outputs": [],
      "source": [
        "def sum_similarity(phrase, topic_list):\n",
        "    score = 0\n",
        "    for topic in topic_list:\n",
        "        try:\n",
        "            similarity = model.wv.similarity(phrase, topic)\n",
        "            # EXPERIMENTAL - to \"reward\" the phrases with a high similarity to a particular category, but maybe not others\n",
        "            if (similarity > 0.50):\n",
        "                # print(\"{} has a high similarity with {}\".format(phrase, topic))\n",
        "                return 1.51\n",
        "            if (similarity > 0):\n",
        "                score += similarity\n",
        "        except:\n",
        "            score += 0\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d6bd72d-a73a-4123-a655-e459d0e0c9e3",
      "metadata": {
        "id": "4d6bd72d-a73a-4123-a655-e459d0e0c9e3"
      },
      "outputs": [],
      "source": [
        "# define topic list and stopwords\n",
        "topic_list = ['politics', 'death', 'kill', 'crime',\n",
        "               'drugs', 'alcohol', 'fat', 'old', 'poor', 'cheap',\n",
        "               'sex', 'sexual',\n",
        "               'employment', 'job', 'disability', 'disabled', \n",
        "               'accident', 'pregnant', 'poop', 'sickness', 'race', 'racial', 'vomit'\n",
        "              ]\n",
        "\n",
        "stopwords = []\n",
        "#['the', 'a', 'to', 'him', 'her', 'them', 'me', 'you', 'of', 'with']\n",
        "\n",
        "with open('stopwords.txt','rb') as f:\n",
        "    content = f.read()\n",
        "    content = content.split(b'\\r\\n')\n",
        "    for line in content:\n",
        "        stopwords.append(line.decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57967be1-b4ae-4b11-a476-4b337dd20d98",
      "metadata": {
        "id": "57967be1-b4ae-4b11-a476-4b337dd20d98"
      },
      "source": [
        "#### Perform topic filtering and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04c02c89-8dca-4152-b11d-449191d9807b",
      "metadata": {
        "id": "04c02c89-8dca-4152-b11d-449191d9807b",
        "outputId": "e6ecd6fd-33d4-4aad-d614-fe6aa9d93e08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(393254, 528250)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define model and train on new data\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec.load(\"TEMP\")\n",
        "# train model on input data - does number of epochs matter?\n",
        "model.train(data, total_examples=len(data), epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "709d0eb6-daff-429c-9104-93859aa1ac70",
      "metadata": {
        "tags": [],
        "id": "709d0eb6-daff-429c-9104-93859aa1ac70",
        "outputId": "66769edf-425c-4da8-c706-f5ed9f527b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retained the euphemism in 1401 out of 1965 sentences\n",
            "13532 quality phrases retained overall\n",
            "Filtered 7243 non-keywords out\n",
            "\n",
            "EXACT SUCCESSES: ['tinkle', 'undocumented immigrants', 'undocumented immigrant', 'venereal diseases', 'venereal disease', 'sex workers', 'sex worker', 'mentally disabled', 'correctional facilities', 'correctional facility', 'freedom fighters', 'freedom fighter', 'detainees', 'detainee', 'psychiatric hospital', 'ethnic cleansing', 'ethnically cleansed', 'enhanced interrogation techniques', 'mistruths', 'elderly', 'armed conflict', 'deceased', 'pro-life', 'income inequality', 'rear end', 'lavatory', 'birds and the bees', 'inner city', 'substance abuse', 'underprivileged', 'inebriated', 'homemaker', 'capital punishment', 'indigent', 'detention camp', 'dearly departed', 'terminating a pregnancy', 'pregnancy termination', 'senior citizen', 'senior citizens', 'substance abuser', 'substance abusers', 'undocumented workers', 'pre-owned', 'sanitation workers', 'latrine', 'plus-sized', 'physically challenged', 'developmentally disabled', 'able-bodied', 'hearing impaired', 'adult beverages', 'fatalities', 'fatality', 'pro-choice', 'targeted killings', 'targeted killing', 'low-income', 'less fortunate', 'mentally challenged', 'droppings', 'portly', 'perished', 'perish', 'passed away', 'neutralize', 'neutralized', 'overweight', 'aging', 'chest', 'demise', 'slim', 'dismissed', 'sober', 'collateral damage', 'deprived', 'plump', 'same-sex', 'stout', 'disabled', 'disadvantaged', 'underdeveloped', 'invalid', 'economical', 'intoxicated', 'regime change', 'exterminate', 'custodian', 'lay off', 'laid off', 'laying off', 'accident', 'gluteus maximus', 'oldest profession', 'experienced', 'outspoken', 'wealthy', 'troubled', 'weed']\n",
            "\n",
            "PARTIAL SUCCESSES: ['ethnic cleansing', 'elderly', 'deceased', 'pro-life', 'substance abuse', 'underprivileged', 'able-bodied', 'fatality', 'pro-choice', 'low-income', 'droppings', 'overweight', 'aging', 'chest', 'demise', 'dismissed', 'same-sex', 'disabled', 'disadvantaged', 'underdeveloped', 'invalid', 'intoxicated', 'accident', 'troubled', 'weed', 'sober', 'expecting', 'late', 'outspoken']\n",
            "\n",
            "FAILURES: ['undocumented immigrants', 'mentally disabled', 'correctional facility', 'detainees', 'comfort women', 'ethnic cleansing', 'lost my lunch', 'lose your lunch', 'lose their lunch', 'mistruth', 'elderly', 'drinking problem', 'deceased', 'pro-life', 'income inequality', 'developing country', 'developed country', 'substance abuse', 'global south', 'underprivileged', 'homemaker', 'differently-abled', 'indigent', 'detention camp', 'economical with the truth', 'pass gas', 'dearly departed', 'substance abusers', 'undocumented workers', 'pre-owned', 'sanitation worker', 'street person', 'full figured', 'custodians', 'same sex', 'under the weather', 'people of color', 'broken home', 'fatality', 'fatalities', 'pro-choice', 'low-income', 'advanced age', 'mentally challenged', 'droppings', 'negative cash flow', 'golden years', 'time of the month', 'made love', 'making love', 'make love', 'running behind', 'let go of', 'let him go', 'letting someone go', 'perish', 'passing on', 'pass on', 'passing away', 'pass away', 'overweight', 'aging', 'collateral damage', 'plump', 'same-sex', 'go all the way', 'disabled', 'special needs', 'disadvantaged', 'underdeveloped', 'mixed up', 'well off', 'over the hill', 'intoxicated', 'exterminate', 'a certain age', 'put to sleep', 'between jobs', 'long sleep', 'getting clean', 'downsize', 'expecting', 'to go to heaven', 'went to heaven', 'accident', 'outlived her usefulness', 'outlived their usefulness', 'got clean', 'late', 'wealthy', 'seeing someone', 'seasoned', 'slept with', 'sleep with', 'sleep around', 'with child', 'weed', 'let them go', 'let us go', 'let her go', 'neutralize', 'chest', 'demise', 'slim', 'dismissed', 'sober', 'economical', 'custodian', 'outlived his usefulness', 'troubled', 'seeing each other']\n",
            "\n",
            "FALSE NEGATIVES of TOPIC FILTERING: ['mistruth', 'differently-abled', 'sanitation worker', 'custodians', 'downsize', 'expecting', 'late', 'seasoned']\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "THRESHOLD = 1.45\n",
        "score = 0\n",
        "\n",
        "successes = []\n",
        "partial_successes = []\n",
        "failures = []\n",
        "topically_filtered_euphs = []\n",
        "quality_phrase_count = 0\n",
        "filtered = []\n",
        "\n",
        "euph_corpus['quality_phrases'] = \"\"\n",
        "\n",
        "for i, row in euph_corpus.iterrows():\n",
        "    text = euph_corpus.loc[i, 'sentence']\n",
        "    #phrases = phraser[text.split()] # use phraser to detect phrases in text\n",
        "    phrases = euph_corpus.loc[i, 'phrases']\n",
        "    euph = euph_corpus.loc[i, 'keyword']\n",
        "    quality_phrases = []\n",
        "    for phrase in phrases:\n",
        "        if (phrase in stopwords):\n",
        "            continue\n",
        "        similarity = sum_similarity(phrase, topic_list)\n",
        "        if (similarity > THRESHOLD and phrase not in quality_phrases):\n",
        "            quality_phrases.append(phrase)\n",
        "        elif (similarity < THRESHOLD and euph == re.sub(r'_', ' ', phrase)):\n",
        "            if euph not in topically_filtered_euphs:\n",
        "                topically_filtered_euphs.append(euph)\n",
        "        else:\n",
        "            filtered.append(phrase)\n",
        "    # add the quality phrases to the column\n",
        "    euph_corpus.at[i, 'quality_phrases'] = quality_phrases\n",
        "    \n",
        "    # now check if the euph in the sentence is retained in the list of quality phrases\n",
        "    quality_phrases = [re.sub(r'_', ' ', p) for p in quality_phrases]\n",
        "    quality_phrase_count += len(quality_phrases)\n",
        "    \n",
        "    if euph in quality_phrases:\n",
        "        score += 1\n",
        "        if euph not in successes:\n",
        "            successes.append(euph)\n",
        "    else:\n",
        "        partial_success = False\n",
        "        for p in quality_phrases: # check if phrase output contains euphemism\n",
        "            if euph in p:\n",
        "                score += 1\n",
        "                if euph not in partial_successes:\n",
        "                    partial_successes.append(euph)\n",
        "                    partial_success = True\n",
        "                    break\n",
        "        if (partial_success == False): \n",
        "            if euph not in failures:\n",
        "                failures.append(euph)\n",
        "\n",
        "            # check failures for a particular phrase\n",
        "            # if (euph == \"ethnic cleansing\"):\n",
        "            #     print(\"TEXT: {}\".format(text))\n",
        "            #     print(\"PHRASES: {}\".format(phrases))\n",
        "            #     print(\"QUALITY PHRASES: {}\".format(quality_phrases))\n",
        "            #     print()\n",
        "\n",
        "print(\"Retained the euphemism in {} out of {} sentences\".format(score, len(euph_corpus)))\n",
        "print(\"{} quality phrases retained overall\".format(quality_phrase_count))\n",
        "print(\"Filtered {} non-keywords out\".format(len(filtered)))\n",
        "print()\n",
        "print(\"EXACT SUCCESSES: {}\".format(successes))\n",
        "print()\n",
        "print(\"PARTIAL SUCCESSES: {}\".format(partial_successes))\n",
        "print()\n",
        "print(\"FAILURES: {}\".format(failures))\n",
        "print()\n",
        "print(\"FALSE NEGATIVES of TOPIC FILTERING: {}\".format(topically_filtered_euphs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "194d9de7-d23f-4b43-9f77-26f87fa262ee",
      "metadata": {
        "tags": [],
        "id": "194d9de7-d23f-4b43-9f77-26f87fa262ee",
        "outputId": "41ad6f38-5709-4a60-d0d3-48c75922d5f3"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"Key 'differently-abled' not present\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15768/1497125601.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msimilarity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_phrase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msimilarity\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.24\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0msimilar_topics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[1;34m(self, w1, w2)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \"\"\"\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key_or_keys)\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(self, key, norm)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[1;34m(self, key, default)\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Key '{key}' not present\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: \"Key 'differently-abled' not present\""
          ]
        }
      ],
      "source": [
        "# testing - for topic similarity queries on a single phrase\n",
        "test_phrase = 'differently-abled'\n",
        "similar_topics = []\n",
        "score = 0\n",
        "for topic in topic_list:\n",
        "    similarity = model.wv.similarity(test_phrase, topic)\n",
        "    if (similarity > 0.24):\n",
        "        similar_topics.append(topic)\n",
        "    if (similarity > 0):\n",
        "        score += similarity\n",
        "    print('{}: {}'.format(topic, similarity))\n",
        "\n",
        "print('SIMILAR TOPICS: {}'.format(similar_topics))\n",
        "print('TOTAL SCORE: {}'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaa0c452-ce5d-428d-9a7e-96a2a34158bf",
      "metadata": {
        "tags": [],
        "id": "aaa0c452-ce5d-428d-9a7e-96a2a34158bf"
      },
      "source": [
        "## Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9103311-5868-499e-b5dc-18cbafedbae4",
      "metadata": {
        "tags": [],
        "id": "d9103311-5868-499e-b5dc-18cbafedbae4",
        "outputId": "0b888fd6-51c6-476d-fee2-9f63eb3d1953"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keyword</th>\n",
              "      <th>edited_text</th>\n",
              "      <th>is_euph</th>\n",
              "      <th>category</th>\n",
              "      <th>type</th>\n",
              "      <th>euph_status</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrases</th>\n",
              "      <th>quality_phrases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tinkle</td>\n",
              "      <td>We're just getting back what was TAKEN from us...</td>\n",
              "      <td>1</td>\n",
              "      <td>bodily functions</td>\n",
              "      <td>tinkle</td>\n",
              "      <td>always_euph</td>\n",
              "      <td>we're just getting back what was taken from us...</td>\n",
              "      <td>[we're, just, getting, back, what, was, taken,...</td>\n",
              "      <td>[greedy, mind, economy, tinkle, bush, mccain]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tinkle</td>\n",
              "      <td>I think AB390 will pass next year now that the...</td>\n",
              "      <td>1</td>\n",
              "      <td>bodily functions</td>\n",
              "      <td>tinkle</td>\n",
              "      <td>always_euph</td>\n",
              "      <td>i think ab390 will pass next year now that the...</td>\n",
              "      <td>[i, think, ab390, will, pass, next_year, now, ...</td>\n",
              "      <td>[pass, protection, fired, tinkle, positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>undocumented immigrants</td>\n",
              "      <td>Singled Out Think Like a Man, the new movie ba...</td>\n",
              "      <td>1</td>\n",
              "      <td>politics</td>\n",
              "      <td>undocumented immigrant</td>\n",
              "      <td>always_euph</td>\n",
              "      <td>anything but secure a federal program designed...</td>\n",
              "      <td>[anything, but, secure, a, federal, program, d...</td>\n",
              "      <td>[federal, program, immigrants, criminal_record...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>undocumented immigrants</td>\n",
              "      <td>Not to be outdone, Sen. Rand Paul (R-Ky. ), so...</td>\n",
              "      <td>1</td>\n",
              "      <td>politics</td>\n",
              "      <td>undocumented immigrant</td>\n",
              "      <td>always_euph</td>\n",
              "      <td>in a post-election interview with politico pau...</td>\n",
              "      <td>[in, a, post-election_interview, with, politic...</td>\n",
              "      <td>[marijuana_laws, immigrants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>undocumented immigrants</td>\n",
              "      <td>The law has also galvanized the growing immigr...</td>\n",
              "      <td>1</td>\n",
              "      <td>politics</td>\n",
              "      <td>undocumented immigrant</td>\n",
              "      <td>always_euph</td>\n",
              "      <td>aside from undocumented immigrants the america...</td>\n",
              "      <td>[aside, from, undocumented_immigrants, the, am...</td>\n",
              "      <td>[undocumented_immigrants, american_citizens, u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>sleep with</td>\n",
              "      <td>There were other photos she wanted me to see: ...</td>\n",
              "      <td>0</td>\n",
              "      <td>sexual activity</td>\n",
              "      <td>sleep with</td>\n",
              "      <td>sometimes_euph</td>\n",
              "      <td>there were other photos she wanted me to see b...</td>\n",
              "      <td>[there, were, other, photos, she, wanted, me, ...</td>\n",
              "      <td>[white, lap, fending_off, sleep, gummy, smile]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>sleep with</td>\n",
              "      <td>I am relieved to see two pup tents marked STAF...</td>\n",
              "      <td>0</td>\n",
              "      <td>sexual activity</td>\n",
              "      <td>sleep with</td>\n",
              "      <td>sometimes_euph</td>\n",
              "      <td>thank god i don't have to sleep with ace wands</td>\n",
              "      <td>[thank, god, i, don't, have, to, sleep, with, ...</td>\n",
              "      <td>[god, sleep, wands]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>sleep around</td>\n",
              "      <td>Nothing serious, just long nights of me hackin...</td>\n",
              "      <td>0</td>\n",
              "      <td>sexual activity</td>\n",
              "      <td>sleep around</td>\n",
              "      <td>sometimes_euph</td>\n",
              "      <td>with all my caterwauling it's a wonder anyone ...</td>\n",
              "      <td>[with, all, my, caterwauling, it's, a, wonder,...</td>\n",
              "      <td>[caterwauling, sleep]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>with child</td>\n",
              "      <td>sounds more like Jonestown. They cant leave @ ...</td>\n",
              "      <td>0</td>\n",
              "      <td>physical/mental attributes</td>\n",
              "      <td>with child</td>\n",
              "      <td>sometimes_euph</td>\n",
              "      <td>they cant leave best advice i can give them is...</td>\n",
              "      <td>[they, cant, leave, best, advice, i, can, give...</td>\n",
              "      <td>[leave, advice, feel, children, danger, phone,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>with child</td>\n",
              "      <td>Nickname of a girl named Diana. 41. What you d...</td>\n",
              "      <td>0</td>\n",
              "      <td>physical/mental attributes</td>\n",
              "      <td>with child</td>\n",
              "      <td>sometimes_euph</td>\n",
              "      <td>what you do with child life 42</td>\n",
              "      <td>[what, you, do, with, child, life, 42]</td>\n",
              "      <td>[child, life]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1965 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      keyword  \\\n",
              "0                      tinkle   \n",
              "1                      tinkle   \n",
              "2     undocumented immigrants   \n",
              "3     undocumented immigrants   \n",
              "4     undocumented immigrants   \n",
              "...                       ...   \n",
              "1960               sleep with   \n",
              "1961               sleep with   \n",
              "1962             sleep around   \n",
              "1963               with child   \n",
              "1964               with child   \n",
              "\n",
              "                                            edited_text  is_euph  \\\n",
              "0     We're just getting back what was TAKEN from us...        1   \n",
              "1     I think AB390 will pass next year now that the...        1   \n",
              "2     Singled Out Think Like a Man, the new movie ba...        1   \n",
              "3     Not to be outdone, Sen. Rand Paul (R-Ky. ), so...        1   \n",
              "4     The law has also galvanized the growing immigr...        1   \n",
              "...                                                 ...      ...   \n",
              "1960  There were other photos she wanted me to see: ...        0   \n",
              "1961  I am relieved to see two pup tents marked STAF...        0   \n",
              "1962  Nothing serious, just long nights of me hackin...        0   \n",
              "1963  sounds more like Jonestown. They cant leave @ ...        0   \n",
              "1964  Nickname of a girl named Diana. 41. What you d...        0   \n",
              "\n",
              "                        category                    type     euph_status  \\\n",
              "0               bodily functions                  tinkle     always_euph   \n",
              "1               bodily functions                  tinkle     always_euph   \n",
              "2                       politics  undocumented immigrant     always_euph   \n",
              "3                       politics  undocumented immigrant     always_euph   \n",
              "4                       politics  undocumented immigrant     always_euph   \n",
              "...                          ...                     ...             ...   \n",
              "1960             sexual activity              sleep with  sometimes_euph   \n",
              "1961             sexual activity              sleep with  sometimes_euph   \n",
              "1962             sexual activity            sleep around  sometimes_euph   \n",
              "1963  physical/mental attributes              with child  sometimes_euph   \n",
              "1964  physical/mental attributes              with child  sometimes_euph   \n",
              "\n",
              "                                               sentence  \\\n",
              "0     we're just getting back what was taken from us...   \n",
              "1     i think ab390 will pass next year now that the...   \n",
              "2     anything but secure a federal program designed...   \n",
              "3     in a post-election interview with politico pau...   \n",
              "4     aside from undocumented immigrants the america...   \n",
              "...                                                 ...   \n",
              "1960  there were other photos she wanted me to see b...   \n",
              "1961     thank god i don't have to sleep with ace wands   \n",
              "1962  with all my caterwauling it's a wonder anyone ...   \n",
              "1963  they cant leave best advice i can give them is...   \n",
              "1964                     what you do with child life 42   \n",
              "\n",
              "                                                phrases  \\\n",
              "0     [we're, just, getting, back, what, was, taken,...   \n",
              "1     [i, think, ab390, will, pass, next_year, now, ...   \n",
              "2     [anything, but, secure, a, federal, program, d...   \n",
              "3     [in, a, post-election_interview, with, politic...   \n",
              "4     [aside, from, undocumented_immigrants, the, am...   \n",
              "...                                                 ...   \n",
              "1960  [there, were, other, photos, she, wanted, me, ...   \n",
              "1961  [thank, god, i, don't, have, to, sleep, with, ...   \n",
              "1962  [with, all, my, caterwauling, it's, a, wonder,...   \n",
              "1963  [they, cant, leave, best, advice, i, can, give...   \n",
              "1964             [what, you, do, with, child, life, 42]   \n",
              "\n",
              "                                        quality_phrases  \n",
              "0         [greedy, mind, economy, tinkle, bush, mccain]  \n",
              "1           [pass, protection, fired, tinkle, positive]  \n",
              "2     [federal, program, immigrants, criminal_record...  \n",
              "3                          [marijuana_laws, immigrants]  \n",
              "4     [undocumented_immigrants, american_citizens, u...  \n",
              "...                                                 ...  \n",
              "1960     [white, lap, fending_off, sleep, gummy, smile]  \n",
              "1961                                [god, sleep, wands]  \n",
              "1962                              [caterwauling, sleep]  \n",
              "1963  [leave, advice, feel, children, danger, phone,...  \n",
              "1964                                      [child, life]  \n",
              "\n",
              "[1965 rows x 9 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "euph_corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c6ca372-a68c-40a0-b74c-de85495a7dda",
      "metadata": {
        "tags": [],
        "id": "9c6ca372-a68c-40a0-b74c-de85495a7dda"
      },
      "source": [
        "#### roBERTa Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e50b4183-9386-4227-9a77-39af5819c9b9",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "e50b4183-9386-4227-9a77-39af5819c9b9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request\n",
        "\n",
        "def load_roberta_sentiment():\n",
        "    # Tasks:\n",
        "    # emoji, emotion, hate, irony, offensive, sentiment\n",
        "    # stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
        "\n",
        "    task='sentiment'\n",
        "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "    # download label mapping\n",
        "    labels=[]\n",
        "    mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "    with urllib.request.urlopen(mapping_link) as f:\n",
        "        html = f.read().decode('utf-8').split(\"\\n\")\n",
        "        csvreader = csv.reader(html, delimiter='\\t')\n",
        "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "    # pretrained\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "    model.save_pretrained(MODEL)\n",
        "    tokenizer.save_pretrained(MODEL)\n",
        "    \n",
        "    return labels, model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3f2d014-f2c2-45d1-86aa-638521641334",
      "metadata": {
        "id": "f3f2d014-f2c2-45d1-86aa-638521641334"
      },
      "source": [
        "#### roBERTa Offensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ec1e38-0915-4a24-8b40-3d4ab7e13a7a",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "tags": [],
        "id": "72ec1e38-0915-4a24-8b40-3d4ab7e13a7a"
      },
      "outputs": [],
      "source": [
        "def load_roberta_offensive():\n",
        "    task='offensive'\n",
        "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "    # download label mapping\n",
        "    labels=[]\n",
        "    mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "    with urllib.request.urlopen(mapping_link) as f:\n",
        "        html = f.read().decode('utf-8').split(\"\\n\")\n",
        "        csvreader = csv.reader(html, delimiter='\\t')\n",
        "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "    # PT\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "    model.save_pretrained(MODEL)\n",
        "    tokenizer.save_pretrained(MODEL)\n",
        "    \n",
        "    return labels, model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4893e394-9a6b-49ae-8d40-8cf8a6253ca7",
      "metadata": {
        "id": "4893e394-9a6b-49ae-8d40-8cf8a6253ca7",
        "outputId": "00800cb3-557d-4c51-a9c8-e5fe5b9cf289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.4909721 0.5090279]\n",
            "[0.5206446  0.47935542]\n"
          ]
        }
      ],
      "source": [
        "#EXPERIMENTAL - function for calculating sentiment score\n",
        "\n",
        "def get_sentiment(s, labels, model, tokenizer):\n",
        "    encoded_input = tokenizer(s, return_tensors='pt')\n",
        "    output = model(**encoded_input)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    ranking = np.argsort(scores)\n",
        "    ranking = ranking[::-1]\n",
        "    for i in range(scores.shape[0]):\n",
        "        l = labels[ranking[i]]\n",
        "        s = scores[ranking[i]]\n",
        "        # print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
        "    return scores\n",
        "\n",
        "def get_offensive(s, labels, model, tokenizer):\n",
        "    encoded_input = tokenizer(s, return_tensors='pt')\n",
        "    output = model(**encoded_input)\n",
        "    scores = output[0][0].detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    ranking = np.argsort(scores)\n",
        "    ranking = ranking[::-1]\n",
        "    for i in range(0, 2):\n",
        "        l = labels[ranking[i]]\n",
        "        s = scores[ranking[i]]\n",
        "        # print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f93756-ee3b-4e3c-a27b-0dce91930cb3",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "e0f93756-ee3b-4e3c-a27b-0dce91930cb3"
      },
      "source": [
        "#### Testing sentence similarity (unfortunately, laid_off has a high similarity score with 'rehired')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40ea87aa-018c-45fc-b4ae-fc7003fd8e3c",
      "metadata": {
        "id": "40ea87aa-018c-45fc-b4ae-fc7003fd8e3c"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# we disable all the annotators except the tokenizer so its fast\n",
        "nlp = English(disable=['tagger', 'parser', 'ner'])\n",
        "\n",
        "def tokenize(text):\n",
        "  return [t.text.lower() for t in nlp(text)]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a095c0-2703-4c60-bd1f-5b2747a33a46",
      "metadata": {
        "id": "48a095c0-2703-4c60-bd1f-5b2747a33a46",
        "outputId": "590f88fa-eb8e-48e7-c501-89bb806b9b2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7555735"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s1 = tokenize('laid_off')\n",
        "s2 = tokenize('rehired')\n",
        "model.wv.n_similarity(s1, s2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84628a6b-fd5a-45f5-9f3b-038da5ea2cd3",
      "metadata": {
        "id": "84628a6b-fd5a-45f5-9f3b-038da5ea2cd3"
      },
      "source": [
        "#### Testing sentiment shifts on a single sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f3efae-7fab-457b-935f-3a3b48071231",
      "metadata": {
        "tags": [],
        "id": "00f3efae-7fab-457b-935f-3a3b48071231",
        "outputId": "7b28e4ee-513a-4902-fe6a-420fa1a452ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "india registered a fifth fatality due to novel coronavirus on friday after an italian national died of covid-19 in rajasthan's jaipur\n",
            "[0.7230875, 0.27123973, 0.005672735, 0.73014456, 0.26985538]\n",
            "\n",
            "india\n",
            "AVERAGE SENTIMENT SHIFTS: [0.26794058084487915, -0.26496194303035736, -0.0029774424619972706, -0.15483760833740234, 0.15483880043029785]\n",
            "MAX INCREASE FROM A PHRASE: [0.046844244, 0.047704726, 0.0011110385, 0.00830394, 0.021167517]\n",
            "PHRASES THAT CAUSED EACH ^: ['south africa', 'germany', 'brazil', 'zimbabwe', 'south africa']\n",
            "TOTAL NEGATIVE INCREASE: 0.4220535159111023\n",
            "TOTAL NEUTRAL INCREASE: 0.15132296085357666\n",
            "TOTAL OFFENSIVE INCREASE: 0.034567296504974365\n",
            "\n",
            "registered\n",
            "AVERAGE SENTIMENT SHIFTS: [-0.9280001521110535, 0.8991212546825409, 0.028880521655082703, 0.11024391651153564, -0.11024245619773865]\n",
            "MAX INCREASE FROM A PHRASE: [0.054001927, 0.1613546, 0.0055799475, 0.022153616, 0.006734699]\n",
            "PHRASES THAT CAUSED EACH ^: ['backordered', 'certifying', 'legally qualified', 're-registered', 'certifying']\n",
            "TOTAL NEGATIVE INCREASE: 0.23988497257232666\n",
            "TOTAL NEUTRAL INCREASE: 1.1356587707996368\n",
            "TOTAL OFFENSIVE INCREASE: 0.12151879072189331\n",
            "\n",
            "fatality\n",
            "AVERAGE SENTIMENT SHIFTS: [0.0751524567604065, -0.08574226498603821, 0.010590845253318548, 0.4275889992713928, -0.4275875389575958]\n",
            "MAX INCREASE FROM A PHRASE: [0.1429503, 0.20715544, 0.006210584, 0.05438596, 0.037530243]\n",
            "PHRASES THAT CAUSED EACH ^: ['life-threatening injuries', 'collision', 'non-fatal', 'collision', 'head trauma']\n",
            "TOTAL NEGATIVE INCREASE: 0.9483960866928101\n",
            "TOTAL NEUTRAL INCREASE: 0.8474223017692566\n",
            "TOTAL OFFENSIVE INCREASE: 0.5269498825073242\n",
            "\n",
            "novel_coronavirus\n",
            "AVERAGE SENTIMENT SHIFTS: [1.2415637373924255, -1.2255284190177917, -0.01603445946238935, -0.47120726108551025, 0.4712086319923401]\n",
            "MAX INCREASE FROM A PHRASE: [0.12653321, 0.03814119, 0.0005265069, 0.02559352, 0.07814145]\n",
            "PHRASES THAT CAUSED EACH ^: ['gastric cancer', 'squamous cell', 'squamous cell', 'multidrug-resistant', 'acute hepatitis']\n",
            "TOTAL NEGATIVE INCREASE: 1.2802314162254333\n",
            "TOTAL NEUTRAL INCREASE: 0.03814119100570679\n",
            "TOTAL OFFENSIVE INCREASE: 0.07258158922195435\n",
            "\n",
            "national\n",
            "AVERAGE SENTIMENT SHIFTS: [-0.4094175696372986, 0.39801260828971863, 0.011405537836253643, -0.0012032389640808105, 0.0012049823999404907]\n",
            "MAX INCREASE FROM A PHRASE: [0.088747084, 0.07376638, 0.0024639396, 0.022340834, 0.08278081]\n",
            "PHRASES THAT CAUSED EACH ^: ['suicide prevention lifeline', 'regional', 'oldest and largest', 'task force', 'suicide prevention lifeline']\n",
            "TOTAL NEGATIVE INCREASE: 0.19830572605133057\n",
            "TOTAL NEUTRAL INCREASE: 0.5940064489841461\n",
            "TOTAL OFFENSIVE INCREASE: 0.12800127267837524\n",
            "\n",
            "died\n",
            "AVERAGE SENTIMENT SHIFTS: [-1.1787689924240112, 1.1554308384656906, 0.023339539067819715, 0.10522204637527466, -0.1052204817533493]\n",
            "MAX INCREASE FROM A PHRASE: [0.104828954, 0.18843761, 0.0043017576, 0.037148654, 0.10741913]\n",
            "PHRASES THAT CAUSED EACH ^: ['died of starvation', 'sought refuge', 'rescued', 'sought refuge', 'raped and murdered']\n",
            "TOTAL NEGATIVE INCREASE: 0.5010765790939331\n",
            "TOTAL NEUTRAL INCREASE: 1.6449501514434814\n",
            "TOTAL OFFENSIVE INCREASE: 0.4270462393760681\n",
            "\n",
            "[('died', 2.5730729699134827), ('fatality', 2.322768270969391), ('registered', 1.4970625340938568), ('novel coronavirus', 1.3909541964530945), ('national', 0.9203134477138519), ('india', 0.6079437732696533)]\n"
          ]
        }
      ],
      "source": [
        "# 815 - passed away\n",
        "# 1232 - laid off\n",
        "# 289 - birds and the bees\n",
        "# 48 - mentally disabled\n",
        "# 61 - correctional facility\n",
        "# 77 - freedom fighters\n",
        "# 155 - enhanced interrogation techniques (! - a diff word is 1st place)\n",
        "# 165 - elderly (! - a diff word is 1st place)\n",
        "# 392 - homemaker (! - actual euph is last place, but PET is 1st place)\n",
        "# 1000 - same-sex (fails)\n",
        "# 1010 - go all the way (fails because intended euph is not detected)\n",
        "# 600 - fatality (! - \"died\" is 1st place, consider weighging scores differently? off > neg > neu)\n",
        "\n",
        "i = 600 # index of a sentence from euph corpus \n",
        "sample_quality_phrases = euph_corpus.loc[i, 'quality_phrases']\n",
        "sample_sentence = euph_corpus.loc[i, 'sentence']\n",
        "sample_keyword = euph_corpus.loc[i, 'keyword']\n",
        "num_paraphrases = 25\n",
        "\n",
        "# load the models\n",
        "sentiment_labels, sentiment_model, sentiment_tokenizer = load_roberta_sentiment()\n",
        "offensive_labels, offensive_model, offensive_tokenizer = load_roberta_offensive()\n",
        "\n",
        "# get the scores for the original sentence\n",
        "print(sample_sentence)\n",
        "orig_scores = list(get_sentiment(sample_sentence, sentiment_labels, sentiment_model, sentiment_tokenizer))\n",
        "orig_scores = orig_scores + list(get_offensive(sample_sentence, offensive_labels, offensive_model, offensive_tokenizer))\n",
        "print(orig_scores)\n",
        "\n",
        "output = []\n",
        "\n",
        "for q in sample_quality_phrases:\n",
        "    sample_paraphrases = []\n",
        "    print()\n",
        "    print(q)\n",
        "    sample_paraphrases = model.wv.most_similar(q, topn = num_paraphrases) # can swap out\n",
        "    \n",
        "    # various sentiment statistics\n",
        "    sentiment_shift = [0, 0, 0, 0, 0]\n",
        "    max_inc = [0, 0, 0, 0, 0]\n",
        "    max_inc_para = [\"\", \"\", \"\", \"\", \"\"]\n",
        "    tot_neg_inc = 0\n",
        "    tot_neu_inc = 0\n",
        "    tot_off_inc = 0\n",
        "    \n",
        "    for p in sample_paraphrases:\n",
        "        p_string = re.sub(r'_', ' ', p[0]) # the underscores are removed for sentiment computation - experiment?\n",
        "        q_string = re.sub(r'_', ' ', q)\n",
        "        # replacement\n",
        "        pattern = re.compile(r'\\b'+q_string+r'\\b', re.IGNORECASE)\n",
        "        new_sentence = pattern.sub(p_string, sample_sentence)\n",
        "        \n",
        "        # print(new_sentence)\n",
        "        # at this point, we could check the integrity of the paraphrase\n",
        "        \n",
        "        # get the sentiment/offensive scores for this paraphrase\n",
        "        scores = list(get_sentiment(new_sentence, sentiment_labels, sentiment_model, sentiment_tokenizer))\n",
        "        scores = scores + list(get_offensive(new_sentence, offensive_labels, offensive_model, offensive_tokenizer))\n",
        "        \n",
        "        # update the quality phrase's sentiment statistics with the sentiment shifts from this paraphrase\n",
        "        shifts = [0, 0, 0, 0, 0]\n",
        "        for i in range(0, len(scores)):\n",
        "            shifts[i] = scores[i] - orig_scores[i]\n",
        "            sentiment_shift[i] += shifts[i]\n",
        "            if (shifts[i] > max_inc[i]):\n",
        "                max_inc[i] = shifts[i]\n",
        "                max_inc_para[i] = p_string\n",
        "        \n",
        "        # update the relevant scores for detection\n",
        "        if (shifts[0] > 0):\n",
        "            tot_neg_inc += shifts[0]\n",
        "        if (shifts[1] > 0):\n",
        "            tot_neu_inc += shifts[1]\n",
        "        if (shifts[3] > 0):\n",
        "            tot_off_inc += shifts[3]\n",
        "        \n",
        "    for val in sentiment_shift:\n",
        "        val /= num_paraphrases\n",
        "    print(\"AVERAGE SENTIMENT SHIFTS: {}\".format(sentiment_shift))\n",
        "    print(\"MAX INCREASE FROM A PHRASE: {}\".format(max_inc))\n",
        "    print(\"PHRASES THAT CAUSED EACH ^: {}\".format(max_inc_para))\n",
        "    print(\"TOTAL NEGATIVE INCREASE: {}\".format(tot_neg_inc))\n",
        "    print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_neu_inc))\n",
        "    print(\"TOTAL OFFENSIVE INCREASE: {}\".format(tot_off_inc))\n",
        "    \n",
        "    output.append((q_string, tot_neg_inc + tot_neu_inc + tot_off_inc))\n",
        "\n",
        "output = list(sorted(output, key=lambda x: x[1], reverse=True))\n",
        "print()\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f985515b-beed-4369-a6b6-7f3f3a5e984e",
      "metadata": {
        "id": "f985515b-beed-4369-a6b6-7f3f3a5e984e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Euph Detection on Euph Corpus 4-3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}