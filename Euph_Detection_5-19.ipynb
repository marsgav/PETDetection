{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7db7b57-593f-402b-9e89-bd9b91b2ebfc",
   "metadata": {},
   "source": [
    "## Testing on euph corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a826d2-feed-40fa-82bc-b522d3378c67",
   "metadata": {},
   "source": [
    "#### Load and preprocess euph sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139ed7ad-2115-4b72-b97a-f1c37bd661c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "euph_corpus = pd.read_csv('data/Euphemism_Corpus_2-24.csv', index_col=0, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf54fb6-1ff6-4b92-932b-a55b2f50d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'(##\\d*\\W)|<\\w>|,|;|:|--|\\(|\\)|#|%|\\\\|\\/|\\.|\\*|\\+|@', '', s)\n",
    "    s = re.sub(r'\\s\\s+', ' ', s)\n",
    "    s = s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346edc29-5cd1-4af3-bfa0-22dc8c95dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess sentences\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    text = euph_corpus.loc[i, 'sentence']\n",
    "    euph_corpus.loc[i, 'sentence'] = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeef0f1e-1224-4a47-88ea-7524a33eb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrasify the sentences\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "\n",
    "bigram_phraser = Phraser.load('data/bigram_phraser_7')\n",
    "trigram_phraser = Phraser.load('data/trigram_phraser_7')\n",
    "euph_corpus['phrases'] = \"\"\n",
    "data = [] # holds phrased input sentences to update wv model with\n",
    "\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    text = euph_corpus.loc[i, 'sentence']\n",
    "    euph_corpus.at[i, 'phrases'] = bigram_phraser[text.split()] # use phraser to detect phrases in text\n",
    "    euph_corpus.at[i, 'phrases'] = trigram_phraser[euph_corpus.loc[i, 'phrases']]\n",
    "    data.append(euph_corpus.loc[i, 'phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26467c31-7785-47b9-9e21-694bcbaff4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'we',\n",
       " 'talking',\n",
       " 'the',\n",
       " 'merits',\n",
       " \"of'\",\n",
       " 'enhanced_interrogation_techniques',\n",
       " 'or',\n",
       " 'the',\n",
       " 'definition_of_torture']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the phraser is still working\n",
    "trigram_phraser[['are', 'we', 'talking', 'the', 'merits', \"of'\", 'enhanced_interrogation', 'techniques', 'or', 'the', 'definition', 'of', 'torture']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e543dfa-0ea0-4c08-9c34-ef8e1ccdaa65",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define topic similarity function, topic list and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f09267-a883-4fc2-83b8-ef3ad151c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_similarity(phrase, topic_list):\n",
    "    score = 0\n",
    "    for topic in topic_list:\n",
    "        try:\n",
    "            similarity = model.wv.similarity(phrase, topic)\n",
    "            if (similarity > 0):\n",
    "                score += similarity\n",
    "        except:\n",
    "            score += 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6bd72d-a73a-4123-a655-e459d0e0c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define topic list and stopwords\n",
    "topic_list = ['politics', 'death', 'kill', 'crime',\n",
    "               'drugs', 'alcohol', 'fat', 'old', 'poor', 'cheap',\n",
    "               'sex', 'sexual',\n",
    "               'employment', 'job', 'disability', 'disabled', \n",
    "               'accident', 'pregnant', 'poop', 'sickness', 'race', 'racial', 'vomit'\n",
    "              ]\n",
    "\n",
    "stopwords = []\n",
    "#['the', 'a', 'to', 'him', 'her', 'them', 'me', 'you', 'of', 'with']\n",
    "\n",
    "with open('data/stopwords.txt','rb') as f:\n",
    "    content = f.read()\n",
    "    content = content.split(b'\\r\\n')\n",
    "    for line in content:\n",
    "        stopwords.append(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57967be1-b4ae-4b11-a476-4b337dd20d98",
   "metadata": {},
   "source": [
    "#### Perform topic filtering and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04c02c89-8dca-4152-b11d-449191d9807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346521, 451540)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model and train on new data\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"data/wv_model_7\") # typically takes 45-90 seconds\n",
    "# train model on input data \n",
    "model.train(data, total_examples=len(data), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "194d9de7-d23f-4b43-9f77-26f87fa262ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics: -0.09195461869239807\n",
      "death: -0.0504598394036293\n",
      "kill: 0.044105637818574905\n",
      "crime: -0.005749249830842018\n",
      "drugs: 0.09508519619703293\n",
      "alcohol: 0.002513594925403595\n",
      "fat: 0.17617137730121613\n",
      "old: 0.20360994338989258\n",
      "poor: 0.23568153381347656\n",
      "cheap: 0.10365447402000427\n",
      "sex: -0.1314983069896698\n",
      "sexual: -0.20578521490097046\n",
      "employment: 0.4224083721637726\n",
      "job: 0.4618397355079651\n",
      "disability: 0.2803969383239746\n",
      "disabled: 0.39359474182128906\n",
      "accident: 0.24307262897491455\n",
      "pregnant: 0.3209178149700165\n",
      "poop: 0.0008516162633895874\n",
      "sickness: 0.1409498155117035\n",
      "race: -0.1082506850361824\n",
      "racial: -0.17647254467010498\n",
      "vomit: -0.07262822240591049\n",
      "SIMILAR TOPICS: ['employment', 'job', 'disability', 'disabled', 'accident', 'pregnant']\n",
      "TOTAL SCORE: 3.1248534210026264\n"
     ]
    }
   ],
   "source": [
    "# TESTING for similarities to topic words on a single phrase\n",
    "test_phrase = 'laid_off'\n",
    "similar_topics = []\n",
    "score = 0\n",
    "for topic in topic_list:\n",
    "    similarity = model.wv.similarity(test_phrase, topic)\n",
    "    if (similarity > 0.24):\n",
    "        similar_topics.append(topic)\n",
    "    if (similarity > 0):\n",
    "        score += similarity\n",
    "    print('{}: {}'.format(topic, similarity))\n",
    "\n",
    "print('SIMILAR TOPICS: {}'.format(similar_topics))\n",
    "print('TOTAL SCORE: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "709d0eb6-daff-429c-9104-93859aa1ac70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained the euphemism in 1626 out of 1965 sentences\n",
      "14787 quality phrases retained overall\n",
      "Filtered 7034 non-keywords out\n",
      "\n",
      "EXACT SUCCESSES: ['tinkle', 'undocumented immigrants', 'undocumented immigrant', 'venereal diseases', 'venereal disease', 'sex workers', 'sex worker', 'mentally disabled', 'correctional facilities', 'correctional facility', 'freedom fighters', 'freedom fighter', 'detainees', 'detainee', 'psychiatric hospital', 'ethnic cleansing', 'ethnically cleansed', 'enhanced interrogation techniques', 'mistruths', 'mistruth', 'elderly', 'armed conflict', 'drinking problem', 'deceased', 'pro-life', 'income inequality', 'rear end', 'lavatory', 'birds and the bees', 'inner city', 'developing country', 'developed country', 'substance abuse', 'global south', 'underprivileged', 'inebriated', 'homemaker', 'capital punishment', 'differently-abled', 'indigent', 'detention camp', 'pass gas', 'dearly departed', 'terminating a pregnancy', 'pregnancy termination', 'senior citizen', 'senior citizens', 'substance abuser', 'substance abusers', 'undocumented workers', 'pre-owned', 'sanitation workers', 'sanitation worker', 'latrine', 'plus-sized', 'physically challenged', 'developmentally disabled', 'custodians', 'same sex', 'able-bodied', 'hearing impaired', 'under the weather', 'people of color', 'adult beverages', 'fatalities', 'fatality', 'pro-choice', 'targeted killings', 'targeted killing', 'low-income', 'less fortunate', 'advanced age', 'mentally challenged', 'droppings', 'portly', 'negative cash flow', 'golden years', 'perished', 'perish', 'passed away', 'passing away', 'pass away', 'neutralize', 'neutralized', 'overweight', 'aging', 'chest', 'demise', 'slim', 'dismissed', 'sober', 'collateral damage', 'deprived', 'plump', 'same-sex', 'stout', 'disabled', 'special needs', 'disadvantaged', 'underdeveloped', 'invalid', 'mixed up', 'economical', 'over the hill', 'intoxicated', 'regime change', 'exterminate', 'custodian', 'put to sleep', 'downsize', 'laid off', 'laying off', 'lay off', 'went to heaven', 'accident', 'gluteus maximus', 'oldest profession', 'late', 'experienced', 'outspoken', 'wealthy', 'troubled', 'seeing someone', 'slept with', 'weed']\n",
      "\n",
      "PARTIAL SUCCESSES: ['undocumented immigrants', 'mentally disabled', 'detainees', 'ethnic cleansing', 'elderly', 'deceased', 'pro-life', 'income inequality', 'rear end', 'inner city', 'substance abuse', 'underprivileged', 'homemaker', 'indigent', 'pre-owned', 'same sex', 'able-bodied', 'fatality', 'fatalities', 'pro-choice', 'low-income', 'less fortunate', 'droppings', 'golden years', 'perished', 'perish', 'neutralize', 'overweight', 'aging', 'chest', 'demise', 'slim', 'dismissed', 'sober', 'collateral damage', 'plump', 'same-sex', 'stout', 'disabled', 'special needs', 'disadvantaged', 'underdeveloped', 'economical', 'intoxicated', 'regime change', 'exterminate', 'expecting', 'lay off', 'laid off', 'laying off', 'accident', 'late', 'outspoken', 'wealthy', 'troubled', 'weed', 'let them go', 'deprived', 'invalid', 'custodian', 'experienced', 'with child']\n",
      "\n",
      "FAILURES: ['undocumented immigrants', 'sex workers', 'mentally disabled', 'correctional facility', 'detainees', 'comfort women', 'ethnic cleansing', 'lost my lunch', 'lose your lunch', 'lose their lunch', 'enhanced interrogation techniques', 'elderly', 'deceased', 'pro-life', 'income inequality', 'rear end', 'inner city', 'developed country', 'developing country', 'substance abuse', 'underprivileged', 'homemaker', 'differently-abled', 'indigent', 'detention camp', 'economical with the truth', 'substance abusers', 'undocumented workers', 'street person', 'full figured', 'same sex', 'able-bodied', 'people of color', 'broken home', 'fatality', 'fatalities', 'pro-choice', 'low-income', 'less fortunate', 'advanced age', 'mentally challenged', 'droppings', 'time of the month', 'made love', 'making love', 'make love', 'running behind', 'let go of', 'let him go', 'letting someone go', 'perished', 'perish', 'passing on', 'pass on', 'neutralize', 'overweight', 'aging', 'chest', 'demise', 'slim', 'dismissed', 'sober', 'collateral damage', 'plump', 'same-sex', 'go all the way', 'stout', 'disabled', 'disadvantaged', 'underdeveloped', 'invalid', 'well off', 'economical', 'intoxicated', 'exterminate', 'a certain age', 'between jobs', 'long sleep', 'getting clean', 'downsize', 'expecting', 'lay off', 'laid off', 'to go to heaven', 'accident', 'outlived her usefulness', 'outlived their usefulness', 'got clean', 'late', 'wealthy', 'troubled', 'seeing someone', 'seasoned', 'sleep with', 'slept with', 'sleep around', 'with child', 'weed', 'let them go', 'let us go', 'let her go', 'pass away', 'regime change', 'custodian', 'outlived his usefulness', 'outspoken', 'seeing each other']\n",
      "\n",
      "FALSE NEGATIVES of TOPIC FILTERING: ['expecting', 'seasoned', 'outlived his usefulness']\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 1.5\n",
    "score = 0\n",
    "\n",
    "successes = []\n",
    "partial_successes = []\n",
    "failures = []\n",
    "topically_filtered_euphs = []\n",
    "quality_phrase_count = 0\n",
    "filtered = []\n",
    "\n",
    "euph_corpus['quality_phrases'] = \"\"\n",
    "\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    text = euph_corpus.loc[i, 'sentence']\n",
    "    phrases = euph_corpus.loc[i, 'phrases']\n",
    "    euph = euph_corpus.loc[i, 'keyword']\n",
    "    quality_phrases = []\n",
    "    for phrase in phrases:\n",
    "        if (phrase in stopwords):\n",
    "            continue\n",
    "        similarity = sum_similarity(phrase, topic_list)\n",
    "        if (similarity > THRESHOLD and phrase not in quality_phrases):\n",
    "            quality_phrases.append(phrase)\n",
    "        elif (similarity < THRESHOLD and euph == re.sub(r'_', ' ', phrase)):\n",
    "            if euph not in topically_filtered_euphs:\n",
    "                topically_filtered_euphs.append(euph)\n",
    "        else:\n",
    "            filtered.append(phrase)\n",
    "    # add the quality phrases to the column\n",
    "    euph_corpus.at[i, 'quality_phrases'] = quality_phrases\n",
    "    \n",
    "    # now check if the euph in the sentence is retained in the list of quality phrases\n",
    "    quality_phrases = [re.sub(r'_', ' ', p) for p in quality_phrases]\n",
    "    quality_phrase_count += len(quality_phrases)\n",
    "    \n",
    "    if euph in quality_phrases:\n",
    "        score += 1\n",
    "        if euph not in successes:\n",
    "            successes.append(euph)\n",
    "    else:\n",
    "        partial_success = False\n",
    "        for p in quality_phrases: # check if phrase output contains euphemism\n",
    "            if euph in p:\n",
    "                score += 1\n",
    "                if euph not in partial_successes:\n",
    "                    partial_successes.append(euph)\n",
    "                    partial_success = True\n",
    "                    break\n",
    "        if (partial_success == False): \n",
    "            if euph not in failures:\n",
    "                failures.append(euph)\n",
    "\n",
    "            # check failures for a particular phrase\n",
    "            # if (euph == \"ethnic cleansing\"):\n",
    "            #     print(\"TEXT: {}\".format(text))\n",
    "            #     print(\"PHRASES: {}\".format(phrases))\n",
    "            #     print(\"QUALITY PHRASES: {}\".format(quality_phrases))\n",
    "            #     print()\n",
    "\n",
    "print(\"Retained the euphemism in {} out of {} sentences\".format(score, len(euph_corpus)))\n",
    "print(\"{} quality phrases retained overall\".format(quality_phrase_count))\n",
    "print(\"Filtered {} non-keywords out\".format(len(filtered)))\n",
    "print()\n",
    "print(\"EXACT SUCCESSES: {}\".format(successes))\n",
    "print()\n",
    "print(\"PARTIAL SUCCESSES: {}\".format(partial_successes))\n",
    "print()\n",
    "print(\"FAILURES: {}\".format(failures))\n",
    "print()\n",
    "print(\"FALSE NEGATIVES of TOPIC FILTERING: {}\".format(topically_filtered_euphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0c452-ce5d-428d-9a7e-96a2a34158bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2697674-4209-4dc6-bc72-c6d979492e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint containing quality phrases\n",
    "euph_corpus = pd.read_csv('Euphemism_Corpus_with_Quality_Phrases_1.csv', encoding='utf-8', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6ca372-a68c-40a0-b74c-de85495a7dda",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### roBERTa Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50b4183-9386-4227-9a77-39af5819c9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "def load_roberta_sentiment():\n",
    "    # Tasks:\n",
    "    # emoji, emotion, hate, irony, offensive, sentiment\n",
    "    # stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "    task='sentiment'\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "    # download label mapping\n",
    "    labels=[]\n",
    "    mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "    with urllib.request.urlopen(mapping_link) as f:\n",
    "        html = f.read().decode('utf-8').split(\"\\n\")\n",
    "        csvreader = csv.reader(html, delimiter='\\t')\n",
    "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "    # pretrained\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    model.save_pretrained(MODEL)\n",
    "    tokenizer.save_pretrained(MODEL)\n",
    "    \n",
    "    return labels, model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2d014-f2c2-45d1-86aa-638521641334",
   "metadata": {},
   "source": [
    "#### roBERTa Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ec1e38-0915-4a24-8b40-3d4ab7e13a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_roberta_offensive():\n",
    "    task='offensive'\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "    # download label mapping\n",
    "    labels=[]\n",
    "    mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "    with urllib.request.urlopen(mapping_link) as f:\n",
    "        html = f.read().decode('utf-8').split(\"\\n\")\n",
    "        csvreader = csv.reader(html, delimiter='\\t')\n",
    "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "    # PT\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    model.save_pretrained(MODEL)\n",
    "    tokenizer.save_pretrained(MODEL)\n",
    "    \n",
    "    return labels, model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4893e394-9a6b-49ae-8d40-8cf8a6253ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for using the roberta models\n",
    "def get_sentiment(s, labels, model, tokenizer):\n",
    "    encoded_input = tokenizer(s, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    # ranking = np.argsort(scores)\n",
    "    # ranking = ranking[::-1]\n",
    "    # for i in range(scores.shape[0]):\n",
    "    #     l = labels[ranking[i]]\n",
    "    #     s = scores[ranking[i]]\n",
    "        # print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    return scores\n",
    "\n",
    "def get_offensive(s, labels, model, tokenizer):\n",
    "    encoded_input = tokenizer(s, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    # ranking = np.argsort(scores)\n",
    "    # ranking = ranking[::-1]\n",
    "    # for i in range(0, 2):\n",
    "    #     l = labels[ranking[i]]\n",
    "    #     s = scores[ranking[i]]\n",
    "        # print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad5eaa9-5ad6-4619-984a-19fedb07e4ce",
   "metadata": {},
   "source": [
    "#### Run sentiment/offensive analysis on euph corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "659d594a-1069-4d20-8106-d6f6f592ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "needs functions load_roberta_sentiment(), load_roberta_offensive(), get_sentiment() and get_offensive()\n",
    "'''\n",
    "def get_top_euph_candidates(text, phrases, num_paraphrases, wv_model, sentiment_pack, offensive_pack, show_stats=False):\n",
    "    \n",
    "    sentiment_labels, sentiment_model, sentiment_tokenizer = sentiment_pack[0], sentiment_pack[1], sentiment_pack[2]\n",
    "    offensive_labels, offensive_model, offensive_tokenizer = offensive_pack[0], offensive_pack[1], offensive_pack[2]\n",
    "    \n",
    "    orig_scores = list(get_sentiment(text, sentiment_labels, sentiment_model, sentiment_tokenizer))\n",
    "    orig_scores = orig_scores + list(get_offensive(text, offensive_labels, offensive_model, offensive_tokenizer))\n",
    "    if show_stats == True: print('SENTIMENT OF ORIGINAL SENTENCE: {}'.format(orig_scores))\n",
    "    phrase_scores = []\n",
    "\n",
    "    for q in phrases:\n",
    "        paraphrases = []\n",
    "        if show_stats == True: print('\\n'+q)\n",
    "        paraphrases = wv_model.wv.most_similar(q, topn = num_paraphrases) # can swap out\n",
    "        \n",
    "        # print(paraphrases)\n",
    "        \n",
    "        # various sentiment statistics\n",
    "        sentiment_shift = [0, 0, 0, 0, 0]\n",
    "        max_inc = [0, 0, 0, 0, 0]\n",
    "        max_inc_para = [\"\", \"\", \"\", \"\", \"\"]\n",
    "        tot_neg_inc = 0\n",
    "        tot_neu_inc = 0\n",
    "        tot_off_inc = 0\n",
    "        tot_noff_inc = 0\n",
    "        \n",
    "        for p in paraphrases:\n",
    "            p_string = re.sub(r'_', ' ', p[0]) # the underscores are removed for sentiment computation - experiment?\n",
    "            q_string = re.sub(r'_', ' ', q)\n",
    "            \n",
    "            if (q_string in p_string):\n",
    "#                 print(\"Paraphrase is superstring, skipping!\")\n",
    "#                 print()\n",
    "                continue\n",
    "\n",
    "            # replacement\n",
    "            pattern = re.compile(r'\\b'+q_string+r'\\b', re.IGNORECASE)\n",
    "            new_sentence = pattern.sub(p_string, text)\n",
    "            # at this point, we could check the integrity of the paraphrase\n",
    "\n",
    "            # get the sentiment/offensive scores for this paraphrase\n",
    "            scores = list(get_sentiment(new_sentence, sentiment_labels, sentiment_model, sentiment_tokenizer))\n",
    "            scores = scores + list(get_offensive(new_sentence, offensive_labels, offensive_model, offensive_tokenizer))\n",
    "\n",
    "            # update the quality phrase's sentiment statistics with the sentiment shifts from this paraphrase\n",
    "            shifts = [0, 0, 0, 0, 0]\n",
    "            for i in range(0, len(scores)):\n",
    "                shifts[i] = scores[i] - orig_scores[i]\n",
    "                sentiment_shift[i] += shifts[i]\n",
    "                if (shifts[i] > max_inc[i]):\n",
    "                    max_inc[i] = shifts[i]\n",
    "                    max_inc_para[i] = p_string\n",
    "\n",
    "            # update the relevant scores for detection\n",
    "            if (shifts[0] > 0):\n",
    "                tot_neg_inc += shifts[0]\n",
    "            if (shifts[1] > 0):\n",
    "                tot_neu_inc += shifts[1]\n",
    "            if (shifts[3] > 0):\n",
    "                tot_noff_inc += shifts[3]\n",
    "            if (shifts[4] > 0):\n",
    "                tot_off_inc += shifts[4]\n",
    "        \n",
    "        for val in sentiment_shift:\n",
    "            val /= num_paraphrases\n",
    "        if (show_stats == True):\n",
    "            print(\"AVERAGE SENTIMENT SHIFTS: {}\".format(sentiment_shift))\n",
    "            print(\"MAX INCREASE FROM A PHRASE: {}\".format(max_inc))\n",
    "            print(\"PHRASES THAT CAUSED EACH ^: {}\".format(max_inc_para))\n",
    "            print(\"TOTAL NEGATIVE INCREASE: {}\".format(tot_neg_inc))\n",
    "            print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_neu_inc))\n",
    "            print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_noff_inc))\n",
    "            print(\"TOTAL OFFENSIVE INCREASE: {}\".format(tot_off_inc))\n",
    "\n",
    "        phrase_scores.append((q_string, tot_neg_inc + tot_neu_inc + 2*(tot_noff_inc + tot_off_inc)))\n",
    "        # alternate scoring schemes\n",
    "        # phrase_scores.append((q_string, max_inc[0] + 2*max_inc[4]))\n",
    "        # phrase_scores.append((q_string, tot_neg_inc + tot_neu_inc + 2*(tot_off_inc)))\n",
    "    phrase_scores = list(sorted(phrase_scores, key=lambda x: x[1], reverse=True))\n",
    "    return phrase_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45b60dec-e610-437c-833d-8113f0df9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "sentiment_labels, sentiment_model, sentiment_tokenizer = load_roberta_sentiment()\n",
    "offensive_labels, offensive_model, offensive_tokenizer = load_roberta_offensive()\n",
    "\n",
    "sentiment_pack = [sentiment_labels, sentiment_model, sentiment_tokenizer]\n",
    "offensive_pack = [offensive_labels, offensive_model, offensive_tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fe47ae8-342f-4071-a9d0-d490a6afbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "num_paraphrases = 25\n",
    "score = 0\n",
    "k = 2 # check the top k candidates for the PET -> success\n",
    "euph_corpus['candidates'] = \"\"\n",
    "euph_corpus['top_2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e8202d5-38d8-48fa-941d-92906b67e0b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 89/1965 [16:21<5:42:08, 10.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 173/1965 [29:28<4:20:42,  8.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 256/1965 [43:10<2:59:04,  6.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 336/1965 [54:12<3:26:44,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 416/1965 [1:09:17<2:05:25,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 508/1965 [1:23:53<3:05:35,  7.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 611/1965 [1:43:39<3:49:19, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 698/1965 [1:56:12<3:18:02,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 819/1965 [2:14:39<2:22:22,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 888/1965 [2:23:00<2:08:47,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 980/1965 [2:36:04<2:48:58, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 1083/1965 [2:52:20<2:39:49, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1195/1965 [3:07:49<1:24:29,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1329/1965 [3:26:49<3:05:32, 17.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1382/1965 [3:36:39<1:31:24,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euphemism detected in 725 out of 1382 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, row in tqdm(euph_corpus.iterrows(), total=euph_corpus.shape[0]):\n",
    "# uncomment below if resuming from checkpoint\n",
    "#     if (0 < i < 600):\n",
    "#         continue\n",
    "    phrases = euph_corpus.loc[i, 'quality_phrases']\n",
    "    \n",
    "    # Converting string to list IF READING FROM CSV as checkpoint\n",
    "    # phrases = ast.literal_eval(phrases)\n",
    "    \n",
    "    text = euph_corpus.loc[i, 'sentence']\n",
    "    euph = euph_corpus.loc[i, 'keyword']\n",
    "    \n",
    "    top_candidates = get_top_euph_candidates(text, phrases, num_paraphrases, model, \n",
    "                                             sentiment_pack, offensive_pack, show_stats=False)\n",
    "#     print(top_candidates)\n",
    "#     print()\n",
    "    euph_corpus.at[i, 'candidates'] = top_candidates\n",
    "    \n",
    "    # check the top k candidates - this code could use cleaning up\n",
    "    for x in range(0, k):\n",
    "        if (len(top_candidates) == 0):\n",
    "            break\n",
    "        if (len(top_candidates) == 1):\n",
    "            candidate = top_candidates[0][0]\n",
    "            if euph in candidate:\n",
    "                score += 1\n",
    "                if (score % 50 == 0):\n",
    "                    print(score)\n",
    "                euph_corpus.loc[i, 'top_2'] = 1\n",
    "            break\n",
    "        candidate = top_candidates[x][0]\n",
    "        if euph in candidate:\n",
    "            score += 1\n",
    "            if (score % 50 == 0):\n",
    "                print(score)\n",
    "            euph_corpus.loc[i, 'top_2'] = 1\n",
    "            break\n",
    "\n",
    "    if (i == 1382):\n",
    "        break\n",
    "print(\"Euphemism detected in {} out of {} sentences\".format(score, 1382))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b2a33a3-614f-41bf-971a-44b935dd04a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "for x in euph_corpus['top_2'].tolist():\n",
    "    if (x == 1):\n",
    "        num_correct += 1\n",
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f985515b-beed-4369-a6b6-7f3f3a5e984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "euph_corpus.to_csv('results_8.3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae9fce9-5a69-4a5a-aa2a-d600e7718903",
   "metadata": {},
   "source": [
    "## Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38148a65-22d2-482d-8514-e31af5e67518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "euph_corpus = pd.read_csv('results_8.3.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30e720-0af6-4f24-b19e-9edef94a2347",
   "metadata": {},
   "source": [
    "#### Print number of 1st, 2nd, and 3rd place PET rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2188bcb-fe52-459f-b3c0-154277887c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "257\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "import ast # this package is helpful for parsing lists stored in CSV files; which contain the literal characters [, ], etc.\n",
    "num_first_place = 0\n",
    "num_second_place = 0\n",
    "num_third_place = 0\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    if (i > 1382):\n",
    "        continue\n",
    "    top_2 = euph_corpus.loc[i, 'top_2']\n",
    "    keyword = euph_corpus.loc[i, 'keyword']\n",
    "    candidates = euph_corpus.loc[i, 'candidates']\n",
    "    # Converting string to list\n",
    "    # candidates = ast.literal_eval(candidates)\n",
    "    if (top_2 == 1):\n",
    "        if (keyword in candidates[0][0]):\n",
    "            num_first_place += 1\n",
    "        elif (keyword in candidates[1][0]):\n",
    "            num_second_place += 1\n",
    "    elif (len(candidates) > 2):\n",
    "        if (keyword in candidates[2][0]):\n",
    "            num_third_place += 1\n",
    "\n",
    "print(num_first_place)\n",
    "print(num_second_place)\n",
    "print(num_third_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67639fe6-6501-48b5-8d9f-2eeb9068ecb1",
   "metadata": {},
   "source": [
    "#### Print number of phrase candidates and target PETs retained after Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dabeae64-67c2-4436-8f50-fd3d15c96213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251\n",
      "31348\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "count = 0\n",
    "tot_p = 0\n",
    "# denote rows where keyword was present in REGULAR phrases\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    if (euph_corpus.loc[i, \"is_euph\"] == 0):\n",
    "        continue\n",
    "    phrases = euph_corpus.loc[i, \"phrases\"]\n",
    "    # Converting string to list\n",
    "    # phrases = ast.literal_eval(phrases)\n",
    "    tot_p += len(phrases)\n",
    "    keyword = euph_corpus.loc[i, 'keyword']\n",
    "    for p in phrases:\n",
    "        p_string = re.sub(r'_', ' ', p)\n",
    "        if keyword in p_string:\n",
    "            #euph_corpus.loc[i, 'keyword_present'] = 1\n",
    "            count += 1\n",
    "            break\n",
    "            \n",
    "print(count) # PETs retained after Phrase Extraction\n",
    "print(tot_p) # total number of phrases remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563aeb1-7f30-4613-adab-c3374189a5d6",
   "metadata": {},
   "source": [
    "#### Print number of phrase candidates and target PETs retained after Phrase Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da585b8f-319f-4830-bbff-e131a8376572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198\n",
      "10503\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "count = 0\n",
    "tot_q = 0\n",
    "# denote rows where keyword was present in quality phrases\n",
    "euph_corpus['keyword_present'] = 0\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    if (euph_corpus.loc[i, \"is_euph\"] == 0):\n",
    "        continue\n",
    "    quality_phrases = euph_corpus.loc[i, \"quality_phrases\"]\n",
    "    # Converting string to list\n",
    "    # quality_phrases = ast.literal_eval(quality_phrases)\n",
    "    tot_q += len(quality_phrases)\n",
    "    keyword = euph_corpus.loc[i, 'keyword']\n",
    "    for q in quality_phrases:\n",
    "        q_string = re.sub(r'_', ' ', q)\n",
    "        if keyword in q_string:\n",
    "            euph_corpus.loc[i, 'keyword_present'] = 1\n",
    "            count += 1\n",
    "            break\n",
    "\n",
    "print(count) # PETs retained after Phrase Filtering\n",
    "print(tot_q) # total number of phrases remaining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed96f10-9af5-4b53-9535-67b56a74c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append whether or not the PET is present in quality_phrases (prior to ranking stage) as a column\n",
    "euph_corpus.to_csv('results_8.2.1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15101dce-5a50-4a5a-a0e4-00537007d6b2",
   "metadata": {},
   "source": [
    "#### Print number of phrase candidates and target PETs retained after Phrase Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d55b51f-ef74-4f96-8d0a-1b10076e2acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2728\n"
     ]
    }
   ],
   "source": [
    "tot_top_2 = 0\n",
    "for i, row in euph_corpus.iterrows():\n",
    "    if (euph_corpus.loc[i, \"is_euph\"] == 0):\n",
    "        continue\n",
    "    phrases = euph_corpus.loc[i, \"candidates\"]\n",
    "    if (len(phrases) == 0):\n",
    "        continue\n",
    "    if (len(phrases) == 1):\n",
    "        tot_top_2 += 1\n",
    "    else: \n",
    "        tot_top_2 += 2\n",
    "    # Converting string to list\n",
    "    # phrases = ast.literal_eval(phrases)\n",
    "    # tot_top_2 += len(phrases)\n",
    "print(tot_top_2) # total number of phrases that are in the top 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641e6a3-8bc0-4d0d-b269-c1858aa8ec19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
