{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183860a6-45a0-4d3d-91a1-7b5ef05e1425",
   "metadata": {},
   "source": [
    "# Test a sentence input\n",
    "Requires these files in the same folder as this notebook:\n",
    "- a bigram_phraser\n",
    "- a trigram_phraser\n",
    "- a word2vec model (3 files: model, syn1neg, and vectors)\n",
    "- a list of stopwords (to ignore as potential euphemisms)\n",
    "\n",
    "Required packages:\n",
    "- gensim\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e594810c-bbc6-4577-a917-b5d1c3a09ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# for discarding overly similar paraphrases\n",
    "from difflib import SequenceMatcher\n",
    "def get_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00c3e7f-57d1-43d8-8059-6e48e1599214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Euph_Detection:\n",
    "    def __init__(self, bigram_phraser, trigram_phraser, w2v_model, stopwords_text, sentiment, offensive):\n",
    "        self.bigram_phraser = Phraser.load(bigram_phraser)\n",
    "        self.trigram_phraser = Phraser.load(trigram_phraser)\n",
    "        self.base_model = Word2Vec.load(w2v_model)\n",
    "        self.model = Word2Vec.load(w2v_model)\n",
    "        # may move the below topic list to another file in the future\n",
    "        self.topic_list = ['politics', 'death', 'kill', 'crime',\n",
    "               'drugs', 'alcohol', 'fat', 'old', 'poor', 'cheap',\n",
    "               'sex', 'sexual',\n",
    "               'employment', 'job', 'disability', 'disabled', \n",
    "               'accident', 'pregnant', 'poop', 'sickness', 'race', 'racial', 'vomit'\n",
    "              ]\n",
    "        self.stopwords = self.read_stopwords(stopwords_text)\n",
    "        # load the sentiment models and pack them together for conciseness\n",
    "        self.sentiment_pack = [x for x in self.load_roberta(sentiment)]\n",
    "        self.offensive_pack = [x for x in self.load_roberta(offensive)]\n",
    "    \n",
    "    def preprocess(self, s):\n",
    "        s = s.strip()\n",
    "        s = re.sub(r'(##\\d*\\W)|<\\w>|,|;|:|--|\\(|\\)|#|%|\\\\|\\/|\\.|\\*|\\+|@', '', s)\n",
    "        s = re.sub(r'\\s\\s+', ' ', s)\n",
    "        s = s.lower()\n",
    "        return s\n",
    "\n",
    "    def get_phrases(self, s):\n",
    "        bigrammed_phrases = self.bigram_phraser[s.split()]\n",
    "        trigrammed_phrases = self.trigram_phraser[bigrammed_phrases]\n",
    "\n",
    "    def sum_similarity(self, phrase, topic_list):\n",
    "        score = 0\n",
    "        for topic in topic_list:\n",
    "            try:\n",
    "                similarity = self.model.wv.similarity(phrase, topic)\n",
    "                # \"reward\" the phrases with a high similarity to a particular category, but maybe not others\n",
    "                if (similarity > 0.50):\n",
    "                    return 1.51\n",
    "                if (similarity > 0):\n",
    "                    score += similarity\n",
    "            except:\n",
    "                score += 0\n",
    "        return score\n",
    "    \n",
    "    def read_stopwords(self, text):\n",
    "        stopwords = []\n",
    "        with open(text,'rb') as f:\n",
    "            content = f.read()\n",
    "            content = content.split(b'\\r\\n')\n",
    "            for line in content:\n",
    "                stopwords.append(line.decode('utf-8'))\n",
    "        return stopwords\n",
    "\n",
    "    def topically_filter_phrases(self, phrases, topic_list, stopwords, THRESHOLD, show_stats=False):\n",
    "        quality_phrases = []\n",
    "        filtered = []\n",
    "\n",
    "        for phrase in phrases:\n",
    "            if (phrase in stopwords):\n",
    "                continue\n",
    "            similarity = self.sum_similarity(phrase, topic_list)\n",
    "\n",
    "            if (show_stats == True):\n",
    "                print(\"{} has a relevance score of {}\".format(phrase, similarity)) #table?\n",
    "\n",
    "            if (similarity > THRESHOLD and phrase not in quality_phrases):\n",
    "                quality_phrases.append(phrase)\n",
    "            else:\n",
    "                filtered.append(phrase)\n",
    "\n",
    "        # if (show_stats == True):\n",
    "        #     print(\"\\nRELEVANT PHRASES: {}\".format(quality_phrases))\n",
    "        #     print(\"IRRELEVANT PHRASES: {}\".format(filtered))\n",
    "        return quality_phrases\n",
    "\n",
    "    def load_roberta(self, task):\n",
    "        # Tasks:\n",
    "        # emoji, emotion, hate, irony, offensive, sentiment\n",
    "        # stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "        # task='sentiment' or 'offensive'\n",
    "        \n",
    "        MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "        # download label mapping\n",
    "        labels=[]\n",
    "        mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "        with urllib.request.urlopen(mapping_link) as f:\n",
    "            html = f.read().decode('utf-8').split(\"\\n\")\n",
    "            csvreader = csv.reader(html, delimiter='\\t')\n",
    "        labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "        # pretrained\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "        model.save_pretrained(MODEL)\n",
    "        tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "        return labels, model, tokenizer\n",
    "        \n",
    "    '''\n",
    "    functions for getting the sentiment \n",
    "    '''\n",
    "    def get_sentiment(self, s, pack):\n",
    "        labels, model, tokenizer = pack[0], pack[1], pack[2]\n",
    "        encoded_input = tokenizer(s, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        return scores\n",
    "    \n",
    "    '''\n",
    "    needs functions load_roberta_sentiment(), load_roberta_offensive(), get_sentiment() and get_offensive()\n",
    "    '''\n",
    "    def get_top_euph_candidates(self, text, phrases, num_paraphrases, wv_model, sentiment_pack, offensive_pack, show_stats=False):\n",
    "        orig_scores = list(self.get_sentiment(text, sentiment_pack))\n",
    "        orig_scores = orig_scores + list(self.get_sentiment(text, offensive_pack))\n",
    "        \n",
    "        if show_stats == True: print('SENTIMENT OF ORIGINAL SENTENCE: {}'.format(orig_scores))\n",
    "        phrase_scores = []\n",
    "\n",
    "        for candidate in tqdm(phrases):\n",
    "            paraphrases = []\n",
    "            if show_stats == True: print('\\n'+candidate)\n",
    "            paraphrases = wv_model.wv.most_similar(candidate, topn = num_paraphrases) # can swap out\n",
    "\n",
    "            # print(paraphrases)\n",
    "\n",
    "            # various sentiment statistics\n",
    "            sentiment_shift = [0, 0, 0, 0, 0]\n",
    "            max_inc = [0, 0, 0, 0, 0]\n",
    "            max_inc_para = [\"\", \"\", \"\", \"\", \"\"]\n",
    "            tot_neg_inc = 0\n",
    "            tot_neu_inc = 0\n",
    "            tot_pos_inc = 0\n",
    "            tot_off_inc = 0\n",
    "            tot_noff_inc = 0\n",
    "\n",
    "            # variables to compute the length ratio feature\n",
    "            length_ratio = 0\n",
    "            tot_para_length = 0\n",
    "            num_para = 0\n",
    "\n",
    "            for p in paraphrases:\n",
    "                p_string = re.sub(r'_', ' ', p[0]) # the underscores are removed for sentiment computation - experiment?\n",
    "                candidate_string = re.sub(r'_', ' ', candidate)\n",
    "\n",
    "                '''FILTERING PARAPHRASES'''\n",
    "                # 1. ignore this paraphrase if it's a superstring of the candidate\n",
    "                # e.g., \"horrible_man\" is not a good paraphrase of \"man\"\n",
    "                if (candidate_string in p_string):\n",
    "                    continue\n",
    "\n",
    "                # 2. ignore this paraphrase if it's too similar to the candidate\n",
    "                # e.g., \"horrible_man\" is not a good paraphrase of \"men\"\n",
    "                if (get_similarity(candidate_string, p_string) > 0.5):\n",
    "                    continue\n",
    "\n",
    "                # 3. ignore this paraphrase if it contains profanity, because it results in high sentiment shifts\n",
    "                #    but should never be a substitute for a euphemism\n",
    "                # TODO: include more profanity\n",
    "                # if ('fuck' in p_string):\n",
    "                #     continue\n",
    "\n",
    "                # 4. ignore this paraphrase if it occurs less than 5 times in the model\n",
    "                #    this helps to eliminate the impact of gibberish\n",
    "                if (wv_model.wv.get_vecattr(p[0], 'count') < 5):\n",
    "                    continue\n",
    "                '''END PARAPHRASE FILTERING'''\n",
    "\n",
    "                # replacement\n",
    "                pattern = re.compile(r'\\b'+candidate_string+r'\\b', re.IGNORECASE)\n",
    "                new_sentence = pattern.sub(p_string, text)\n",
    "                # at this point, we could check the integrity of the paraphrase\n",
    "\n",
    "                # get the sentiment/offensive scores for this paraphrase\n",
    "                scores = list(self.get_sentiment(new_sentence, sentiment_pack))\n",
    "                scores = scores + list(self.get_sentiment(new_sentence, offensive_pack))\n",
    "                \n",
    "                # update the quality phrase's sentiment statistics with the sentiment shifts from this paraphrase\n",
    "                shifts = [0, 0, 0, 0, 0]\n",
    "                for i in range(0, len(scores)):\n",
    "                    shifts[i] = scores[i] - orig_scores[i]\n",
    "                    sentiment_shift[i] += shifts[i]\n",
    "                    if (shifts[i] > max_inc[i]):\n",
    "                        max_inc[i] = shifts[i]\n",
    "                        max_inc_para[i] = p_string\n",
    "\n",
    "                # update the relevant scores for detection\n",
    "                if (shifts[0] > 0):\n",
    "                    tot_neg_inc += shifts[0]\n",
    "                if (shifts[1] > 0):\n",
    "                    tot_neu_inc += shifts[1]\n",
    "                if (shifts[2] > 0):\n",
    "                    tot_pos_inc += shifts[2]\n",
    "                if (shifts[3] > 0):\n",
    "                    tot_noff_inc += shifts[3]\n",
    "                if (shifts[4] > 0):\n",
    "                    tot_off_inc += shifts[4]\n",
    "\n",
    "                # update counts for length ratio\n",
    "                num_para += 1\n",
    "                tot_para_length += len(p_string)\n",
    "\n",
    "            # compute length ratio feature\n",
    "            if (num_para != 0):\n",
    "                avg_para_length = tot_para_length / num_para\n",
    "                length_ratio = len(candidate_string) / avg_para_length\n",
    "            # print(length_ratio)\n",
    "            # break\n",
    "\n",
    "            for val in sentiment_shift:\n",
    "                val /= num_paraphrases\n",
    "            if (show_stats == True):\n",
    "                print(\"AVERAGE SENTIMENT SHIFTS: {}\".format(sentiment_shift))\n",
    "                print(\"MAX INCREASE FROM A PHRASE: {}\".format(max_inc))\n",
    "                print(\"PHRASES THAT CAUSED EACH ^: {}\".format(max_inc_para))\n",
    "                print(\"TOTAL NEGATIVE INCREASE: {}\".format(tot_neg_inc))\n",
    "                print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_neu_inc))\n",
    "                print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_noff_inc))\n",
    "                print(\"TOTAL OFFENSIVE INCREASE: {}\".format(tot_off_inc))\n",
    "\n",
    "            # compute the score using the weights from linear regression on the 5 sentiment scores and length ratio feature\n",
    "            phrase_scores.append((candidate_string, 0.02183689*tot_neg_inc + 0.01949368*tot_neu_inc + 0.09130243*tot_noff_inc + 0.12983809 *tot_off_inc + 0.15030182*length_ratio))\n",
    "            \n",
    "        phrase_scores = list(sorted(phrase_scores, key=lambda x: x[1], reverse=True))\n",
    "        return phrase_scores\n",
    "    \n",
    "    def detect_euphs(self, s, topic_threshold, num_paraphrases, show_stats=False):\n",
    "        s = self.preprocess(s)\n",
    "        print(s)\n",
    "\n",
    "        bigrammed_phrases = self.bigram_phraser[s.split()]\n",
    "        trigrammed_phrases = self.trigram_phraser[bigrammed_phrases]\n",
    "        print(\"\\nDETECTED PHRASES: {}\".format(trigrammed_phrases))\n",
    "\n",
    "        data = []\n",
    "        data.append(trigrammed_phrases)\n",
    "        # train model on input data\n",
    "        self.model.train(data, total_examples=len(data), epochs=10)\n",
    "\n",
    "        quality_phrases = self.topically_filter_phrases(trigrammed_phrases, self.topic_list, self.stopwords, topic_threshold, show_stats)\n",
    "        print(\"\\nRELEVANT PHRASES: {}\".format(quality_phrases))\n",
    "\n",
    "        candidate_list = self.get_top_euph_candidates(s, quality_phrases, num_paraphrases, \n",
    "                                            self.model, self.sentiment_pack, self.offensive_pack, \n",
    "                                            show_stats)\n",
    "        \n",
    "        self.model = self.base_model # reset\n",
    "        \n",
    "        return candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a6dd55a-0ba9-450b-8b83-994b81156ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup took 69.74314403533936 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "euph_detector = Euph_Detection('data/bigram_phraser_7', 'data/trigram_phraser_7', \n",
    "                               'data/wv_model_7', 'data/stopwords.txt', \n",
    "                               'sentiment', 'offensive')\n",
    "print(\"Setup took {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce303206-46ad-453d-8e81-8af62e74caa1",
   "metadata": {},
   "source": [
    "#### Input your sentence below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff95dfd0-9994-44ac-8d11-3f9bba425f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we don't know how bad things will get morocco said but it's critical to limit the spread of the virus by honoring the calls for social distancing and by not rushing to the hospital if we feel a bit under the weather\n",
      "\n",
      "DETECTED PHRASES: [\"we_don't\", 'know_how', 'bad_things', 'will_get', 'morocco', 'said', 'but', \"it's\", 'critical', 'to', 'limit_the_spread', 'of', 'the', 'virus', 'by', 'honoring', 'the', 'calls', 'for', 'social_distancing', 'and', 'by', 'not', 'rushing', 'to', 'the', 'hospital', 'if_we', 'feel_a_bit', 'under_the_weather']\n",
      "\n",
      "RELEVANT PHRASES: ['know_how', 'bad_things', 'critical', 'limit_the_spread', 'virus', 'social_distancing', 'rushing', 'hospital', 'if_we', 'feel_a_bit', 'under_the_weather']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:24<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EUPH CANDIDATE RANKING: [('under the weather', 0.31994708311037745), ('limit the spread', 0.2076849393645232), ('social distancing', 0.18775501163216696), ('virus', 0.1715375309333847), ('feel a bit', 0.15883262481811816), ('rushing', 0.14860603544614343), ('know how', 0.1400280180507521), ('hospital', 0.11456183642643182), ('critical', 0.11427736258451968), ('if we', 0.10781739292150148), ('bad things', 0.0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"we don't know how bad things will get morocco said but it's critical to limit the spread of the virus by honoring the calls for social distancing and by not rushing to the hospital if we feel a bit under the weather\"\n",
    "candidate_ranking = euph_detector.detect_euphs(s, topic_threshold=1.45, num_paraphrases=25, show_stats=False)\n",
    "\n",
    "print(\"\\nEUPH CANDIDATE RANKING: {}\".format(candidate_ranking))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7a913-ad6c-4dff-97ef-16d99de62021",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyzing the Process\n",
    "After running Euph_Detection on a sentence, you can further look at the intermediate outputs for a specific candidate phrase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680ebea-a5bc-4c71-bc40-4d6a3a266048",
   "metadata": {},
   "source": [
    "#### Topic Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c992752-906b-4a98-9a6b-41b29f00b845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics: -0.12178656458854675\n",
      "death: 0.3376462459564209\n",
      "kill: 0.37465864419937134\n",
      "crime: 0.2576283812522888\n",
      "drugs: 0.4533570110797882\n",
      "alcohol: 0.315814733505249\n",
      "fat: 0.2738639712333679\n",
      "old: 0.13116423785686493\n",
      "poor: 0.03396809101104736\n",
      "cheap: 0.036798909306526184\n",
      "sex: 0.18742014467716217\n",
      "sexual: 0.13066315650939941\n",
      "employment: -0.01607104018330574\n",
      "job: 0.09143663942813873\n",
      "disability: 0.1916699856519699\n",
      "disabled: 0.31440800428390503\n",
      "accident: 0.35817182064056396\n",
      "pregnant: 0.2856043577194214\n",
      "poop: 0.268268346786499\n",
      "sickness: 0.4311104714870453\n",
      "race: 0.05317165330052376\n",
      "racial: 0.04802703857421875\n",
      "vomit: 0.2797028422355652\n",
      "SIMILAR TOPICS: ['death', 'kill', 'crime', 'drugs', 'alcohol', 'fat', 'disabled', 'accident', 'pregnant', 'poop', 'sickness', 'vomit']\n",
      "TOTAL SCORE: 4.854554686695337\n"
     ]
    }
   ],
   "source": [
    "test_phrase = 'virus'\n",
    "similar_topics = []\n",
    "\n",
    "topic_list = euph_detector.topic_list\n",
    "model = euph_detector.model\n",
    "\n",
    "score = 0\n",
    "for topic in topic_list:\n",
    "    similarity = model.wv.similarity(test_phrase, topic)\n",
    "    if (similarity > 0.25):\n",
    "        similar_topics.append(topic)\n",
    "    if (similarity > 0):\n",
    "        score += similarity\n",
    "    print('{}: {}'.format(topic, similarity))\n",
    "\n",
    "print('SIMILAR TOPICS: {}'.format(similar_topics))\n",
    "print('TOTAL SCORE: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727aec8-f2a7-484d-a9cc-c31ca8634b58",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "beaf9c28-1d80-4617-b957-0a7ebe01f0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT OF ORIGINAL SENTENCE: [0.57720906, 0.38477147, 0.038019482, 0.82404214, 0.17595792]\n",
      "\n",
      "under_the_weather\n",
      "out of sorts\n",
      "[0.024811089, -0.019412309, -0.0053988285, 0.0049026012, -0.004902616]\n",
      "very hungry\n",
      "[0.021269977, -0.019729972, -0.0015399233, -0.021305442, 0.021305427]\n",
      "bummed out\n",
      "[0.08563852, -0.07549262, -0.010145988, -0.05189395, 0.051893875]\n",
      "hungover\n",
      "[0.02169627, -0.022473186, 0.00077697635, -0.027323782, 0.027323678]\n",
      "really busy\n",
      "[-0.02429837, 0.017496675, 0.006801784, 0.017013133, -0.017013296]\n",
      "antsy\n",
      "[0.00614655, -0.006093055, -5.3409487e-05, 0.0010698438, -0.0010699332]\n",
      "frazzled\n",
      "[0.061351597, -0.053379625, -0.00797216, -0.03724599, 0.03724593]\n",
      "nauseated\n",
      "[0.10907304, -0.097510934, -0.01156217, -0.045651138, 0.04565108]\n",
      "homesick\n",
      "[0.015963435, -0.015984803, 2.1286309e-05, -0.0056694746, 0.0056694746]\n",
      "ashamed of myself\n",
      "[0.102668166, -0.08913267, -0.013535535, -0.056426883, 0.056426764]\n",
      "lightheaded\n",
      "[0.046756208, -0.04097554, -0.0057807453, -0.029704332, 0.029704273]\n",
      "really hungry\n",
      "[0.022305608, -0.021760374, -0.0005452931, -0.043115735, 0.04311569]\n",
      "always hungry\n",
      "[0.00031793118, -0.00089746714, 0.0005794242, -0.027837038, 0.027836978]\n",
      "running late\n",
      "[-0.008297563, 0.008529395, -0.00023191795, 0.01907444, -0.019074425]\n",
      "feeling sick\n",
      "[0.09352803, -0.08442178, -0.009106185, -0.06494486, 0.06494476]\n",
      "very tired\n",
      "[0.05743301, -0.053341806, -0.0040911734, 0.0059036016, -0.005903691]\n",
      "crabby\n",
      "[0.039166868, -0.034931928, -0.004234962, -0.009583294, 0.00958322]\n",
      "emotionally drained\n",
      "[0.037840426, -0.03208804, -0.0057525747, -0.016269088, 0.016269058]\n",
      "stiff and sore\n",
      "[0.05836624, -0.050605, -0.007761199, -0.017233074, 0.017233029]\n",
      "sleep deprived\n",
      "[0.043917358, -0.03686443, -0.007052848, -0.029127479, 0.029127479]\n",
      "fatigued\n",
      "[0.03862697, -0.03348884, -0.0051381364, -0.0049464107, 0.0049464107]\n",
      "too exhausted\n",
      "[0.04090154, -0.036673278, -0.0042283386, -0.0034829974, 0.0034829825]\n",
      "apprehensive\n",
      "[-0.029021382, 0.02835244, 0.0006690137, 0.01583618, -0.015836194]\n",
      "very sleepy\n",
      "[0.008496761, -0.010333627, 0.0018368363, -0.005788803, 0.0057887733]\n",
      "short of breath\n",
      "[0.031399846, -0.026274085, -0.005125746, -0.0062497854, 0.006249711]\n",
      "AVERAGE SENTIMENT SHIFTS: [0.906058132648468, -0.8074868619441986, -0.09857181459665298, -0.4399997591972351, 0.43999843299388885]\n",
      "MAX INCREASE FROM A PHRASE: [0.10907304, 0.02835244, 0.006801784, 0.01907444, 0.06494476]\n",
      "PHRASES THAT CAUSED EACH ^: ['nauseated', 'apprehensive', 'really busy', 'running late', 'feeling sick']\n",
      "TOTAL NEGATIVE INCREASE: 0.9676754474639893\n",
      "TOTAL NEUTRAL INCREASE: 0.054378509521484375\n",
      "TOTAL NEUTRAL INCREASE: 0.06379979848861694\n",
      "TOTAL OFFENSIVE INCREASE: 0.5037985891103745\n",
      "LENGTH RATIO: 1.5070921985815604\n",
      "[('under the weather', 0.31994708311037745)]\n"
     ]
    }
   ],
   "source": [
    "text = s\n",
    "q = 'under_the_weather'\n",
    "\n",
    "sentiment_pack = euph_detector.sentiment_pack\n",
    "offensive_pack = euph_detector.offensive_pack\n",
    "model = euph_detector.model\n",
    "\n",
    "orig_scores = list(euph_detector.get_sentiment(s, sentiment_pack))\n",
    "orig_scores = orig_scores + list(euph_detector.get_sentiment(text, offensive_pack))\n",
    "print('SENTIMENT OF ORIGINAL SENTENCE: {}'.format(orig_scores))\n",
    "phrase_scores = []\n",
    "num_paraphrases=25\n",
    "paraphrases = []\n",
    "print('\\n'+q)\n",
    "paraphrases = model.wv.most_similar(q, topn = num_paraphrases) # can swap out\n",
    "\n",
    "# various sentiment statistics\n",
    "sentiment_shift = [0, 0, 0, 0, 0] # [neg, neu, pos, off, n-off]\n",
    "max_inc = [0, 0, 0, 0, 0]\n",
    "max_inc_para = [\"\", \"\", \"\", \"\", \"\"]\n",
    "tot_neg_inc = 0\n",
    "tot_neu_inc = 0\n",
    "tot_pos_inc = 0\n",
    "tot_noff_inc = 0\n",
    "tot_off_inc = 0\n",
    "\n",
    "length_ratio = 0\n",
    "tot_para_length = 0\n",
    "num_para = 0\n",
    "\n",
    "for p in paraphrases:\n",
    "    p_string = re.sub(r'_', ' ', p[0]) # the underscores are removed for sentiment computation - experiment?\n",
    "    q_string = re.sub(r'_', ' ', q)\n",
    "\n",
    "    '''FILTERING PARAPHRASES'''\n",
    "    # filtering out paraphrases if they're a superstring\n",
    "    if (q_string in p_string):\n",
    "#                 print(\"Paraphrase is superstring, skipping!\")\n",
    "#                 print()\n",
    "        continue\n",
    "\n",
    "    # filtering out paraphrases if they're too similar\n",
    "    if (get_similarity(q_string, p_string) > 0.5):\n",
    "        continue\n",
    "\n",
    "    if ('fuck' in p_string):\n",
    "        continue\n",
    "\n",
    "    if (model.wv.get_vecattr(p[0], 'count') < 5):\n",
    "        continue\n",
    "\n",
    "    '''END PARAPHRASE FILTERING'''\n",
    "\n",
    "    # replacement\n",
    "    pattern = re.compile(r'\\b'+q_string+r'\\b', re.IGNORECASE)\n",
    "    new_sentence = pattern.sub(p_string, text)\n",
    "    # at this point, we could check the integrity of the paraphrase\n",
    "\n",
    "    # get the sentiment/offensive scores for this paraphrase\n",
    "    # scores = list(self.get_sentiment(new_sentence, sentiment_labels, sentiment_model, sentiment_tokenizer))\n",
    "    # scores = scores + list(self.get_offensive(new_sentence, offensive_labels, offensive_model, offensive_tokenizer))\n",
    "    scores = list(euph_detector.get_sentiment(new_sentence, sentiment_pack))\n",
    "    scores = scores + list(euph_detector.get_sentiment(new_sentence, offensive_pack))\n",
    "\n",
    "    # update the quality phrase's sentiment statistics with the sentiment shifts from this paraphrase\n",
    "    shifts = [0, 0, 0, 0, 0]\n",
    "    for i in range(0, len(scores)):\n",
    "        shifts[i] = scores[i] - orig_scores[i]\n",
    "        sentiment_shift[i] += shifts[i]\n",
    "        if (shifts[i] > max_inc[i]):\n",
    "            max_inc[i] = shifts[i]\n",
    "            max_inc_para[i] = p_string\n",
    "\n",
    "    # update the relevant scores for detection\n",
    "    if (shifts[0] > 0):\n",
    "        tot_neg_inc += shifts[0]\n",
    "    if (shifts[1] > 0):\n",
    "        tot_neu_inc += shifts[1]\n",
    "    if (shifts[2] > 0):\n",
    "        tot_pos_inc += shifts[2]\n",
    "    if (shifts[3] > 0):\n",
    "        tot_noff_inc += shifts[3]\n",
    "    if (shifts[4] > 0):\n",
    "        tot_off_inc += shifts[4]\n",
    "    \n",
    "    print(p_string)\n",
    "    print(shifts)\n",
    "    # update counts for length ratio\n",
    "    num_para += 1\n",
    "    tot_para_length += len(p_string)\n",
    "\n",
    "# compute length ratio feature\n",
    "if (num_para != 0):\n",
    "    avg_para_length = tot_para_length / num_para\n",
    "    length_ratio = len(q_string) / avg_para_length\n",
    "#         print(length_ratio)\n",
    "#         break\n",
    "\n",
    "for val in sentiment_shift:\n",
    "    val /= num_paraphrases\n",
    "\n",
    "print(\"AVERAGE SENTIMENT SHIFTS: {}\".format(sentiment_shift))\n",
    "print(\"MAX INCREASE FROM A PHRASE: {}\".format(max_inc))\n",
    "print(\"PHRASES THAT CAUSED EACH ^: {}\".format(max_inc_para))\n",
    "print(\"TOTAL NEGATIVE INCREASE: {}\".format(tot_neg_inc))\n",
    "print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_neu_inc))\n",
    "print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_noff_inc))\n",
    "print(\"TOTAL OFFENSIVE INCREASE: {}\".format(tot_off_inc))\n",
    "print(\"LENGTH RATIO: {}\".format(length_ratio))\n",
    "\n",
    "# phrase_scores.append((q_string, tot_neg_inc + tot_neu_inc + 2*(tot_noff_inc + tot_off_inc)))\n",
    "# phrase_scores.append((q_string, 0.02337676*tot_neg_inc + 0.02267515*tot_neu_inc + 0.09802046*tot_noff_inc + 0.14442855*tot_off_inc))\n",
    "# 0.01125929*tot_pos_inc\n",
    "phrase_scores.append((q_string, 0.02183689*tot_neg_inc + 0.01949368*tot_neu_inc + 0.09130243*tot_noff_inc + 0.12983809 *tot_off_inc + 0.15030182*length_ratio))\n",
    "\n",
    "# phrase_scores.append((q_string, max_inc[0] + 2*max_inc[4]))\n",
    "# phrase_scores.append((q_string, tot_neg_inc + tot_neu_inc + 2*(tot_off_inc)))\n",
    "phrase_scores = list(sorted(phrase_scores, key=lambda x: x[1], reverse=True))\n",
    "print(phrase_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8b13e-618d-4089-b942-30c3e9a75eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
