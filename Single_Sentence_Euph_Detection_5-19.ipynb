{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183860a6-45a0-4d3d-91a1-7b5ef05e1425",
   "metadata": {},
   "source": [
    "# Test a sentence input\n",
    "Requires these files in the same folder as this notebook:\n",
    "- a bigram_phraser\n",
    "- a trigram_phraser\n",
    "- a word2vec model (3 files: model, syn1neg, and vectors)\n",
    "- a list of stopwords (to ignore as potential euphemisms)\n",
    "\n",
    "Required packages:\n",
    "- gensim\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e594810c-bbc6-4577-a917-b5d1c3a09ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phraser, Phrases\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a9cb65-a08b-4e80-8ceb-e512be404724",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Euph_Detection:\n",
    "    def __init__(self, bigram_phraser, trigram_phraser, w2v_model, stopwords_text, sentiment, offensive):\n",
    "        self.bigram_phraser = Phraser.load(bigram_phraser)\n",
    "        self.trigram_phraser = Phraser.load(trigram_phraser)\n",
    "        self.base_model = Word2Vec.load(w2v_model)\n",
    "        self.model = Word2Vec.load(w2v_model)\n",
    "        # self.model = KeyedVectors.load(w2v_model)\n",
    "        self.topic_list = ['politics', 'death', 'kill', 'crime',\n",
    "               'drugs', 'alcohol', 'fat', 'old', 'poor', 'cheap',\n",
    "               'sex', 'sexual',\n",
    "               'employment', 'job', 'disability', 'disabled', \n",
    "               'accident', 'pregnant', 'poop', 'sickness', 'race', 'racial', 'vomit'\n",
    "              ]\n",
    "        self.stopwords = self.read_stopwords(stopwords_text)\n",
    "        # load the sentiment models\n",
    "        # sentiment_labels, sentiment_model, sentiment_tokenizer = self.load_roberta(sentiment)\n",
    "        # offensive_labels, offensive_model, offensive_tokenizer = self.load_roberta(offensive)\n",
    "        # pack them together - just for conciseness\n",
    "        self.sentiment_pack = [x for x in self.load_roberta(sentiment)]\n",
    "        self.offensive_pack = [x for x in self.load_roberta(offensive)]\n",
    "    \n",
    "    def preprocess(self, s):\n",
    "        s = s.strip()\n",
    "        s = re.sub(r'(##\\d*\\W)|<\\w>|,|;|:|--|\\(|\\)|#|%|\\\\|\\/|\\.|\\*|\\+|@', '', s)\n",
    "        s = re.sub(r'\\s\\s+', ' ', s)\n",
    "        s = s.lower()\n",
    "        return s\n",
    "\n",
    "    def get_phrases(self, s):\n",
    "        bigrammed_phrases = self.bigram_phraser[s.split()]\n",
    "        trigrammed_phrases = self.trigram_phraser[bigrammed_phrases]\n",
    "\n",
    "    def sum_similarity(self, phrase, topic_list):\n",
    "        score = 0\n",
    "        for topic in topic_list:\n",
    "            try:\n",
    "                similarity = self.model.wv.similarity(phrase, topic)\n",
    "                # EXPERIMENTAL - to \"reward\" the phrases with a high similarity to a particular category, but maybe not others\n",
    "                if (similarity > 0.50):\n",
    "                    # print(\"{} has a high similarity with {}\".format(phrase, topic))\n",
    "                    return 1.51\n",
    "                if (similarity > 0):\n",
    "                    score += similarity\n",
    "            except:\n",
    "                score += 0\n",
    "        return score\n",
    "    \n",
    "    def read_stopwords(self, text):\n",
    "        stopwords = []\n",
    "        with open(text,'rb') as f:\n",
    "            content = f.read()\n",
    "            content = content.split(b'\\r\\n')\n",
    "            for line in content:\n",
    "                stopwords.append(line.decode('utf-8'))\n",
    "        return stopwords\n",
    "\n",
    "    def topically_filter_phrases(self, phrases, topic_list, stopwords, THRESHOLD, show_stats=False):\n",
    "        quality_phrases = []\n",
    "        filtered = []\n",
    "\n",
    "        for phrase in phrases:\n",
    "            if (phrase in stopwords):\n",
    "                continue\n",
    "            similarity = self.sum_similarity(phrase, topic_list)\n",
    "\n",
    "            if (show_stats == True):\n",
    "                print(\"{} has a relevance score of {}\".format(phrase, similarity)) #table?\n",
    "\n",
    "            if (similarity > THRESHOLD and phrase not in quality_phrases):\n",
    "                quality_phrases.append(phrase)\n",
    "            else:\n",
    "                filtered.append(phrase)\n",
    "\n",
    "        # if (show_stats == True):\n",
    "        #     print(\"\\nRELEVANT PHRASES: {}\".format(quality_phrases))\n",
    "        #     print(\"IRRELEVANT PHRASES: {}\".format(filtered))\n",
    "        return quality_phrases\n",
    "\n",
    "    def load_roberta(self, task):\n",
    "        # Tasks:\n",
    "        # emoji, emotion, hate, irony, offensive, sentiment\n",
    "        # stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "        # task='sentiment' or 'offensive'\n",
    "        MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "        # download label mapping\n",
    "        labels=[]\n",
    "        mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "        with urllib.request.urlopen(mapping_link) as f:\n",
    "            html = f.read().decode('utf-8').split(\"\\n\")\n",
    "            csvreader = csv.reader(html, delimiter='\\t')\n",
    "        labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "        # pretrained\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "        model.save_pretrained(MODEL)\n",
    "        tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "        return labels, model, tokenizer\n",
    "        \n",
    "    '''\n",
    "    functions for getting the sentiment \n",
    "    '''\n",
    "    def get_sentiment(self, s, pack):\n",
    "        labels, model, tokenizer = pack[0], pack[1], pack[2]\n",
    "        encoded_input = tokenizer(s, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        return scores\n",
    "    \n",
    "    '''\n",
    "    needs functions load_roberta_sentiment(), load_roberta_offensive(), get_sentiment() and get_offensive()\n",
    "    '''\n",
    "    def get_top_euph_candidates(self, text, phrases, num_paraphrases, wv_model, sentiment_pack, offensive_pack, show_stats=False):\n",
    "        orig_scores = list(self.get_sentiment(text, sentiment_pack))\n",
    "        orig_scores = orig_scores + list(self.get_sentiment(text, offensive_pack))\n",
    "        if show_stats == True: print('SENTIMENT OF ORIGINAL SENTENCE: {}'.format(orig_scores))\n",
    "        phrase_scores = []\n",
    "\n",
    "        for q in tqdm(phrases):\n",
    "            paraphrases = []\n",
    "            if show_stats == True: print('\\n'+q)\n",
    "            paraphrases = wv_model.wv.most_similar(q, topn = num_paraphrases) # can swap out\n",
    "            # print(q)\n",
    "            # print(paraphrases)\n",
    "            \n",
    "            # various sentiment statistics\n",
    "            sentiment_shift = [0, 0, 0, 0, 0] # [neg, neu, pos, off, n-off]\n",
    "            max_inc = [0, 0, 0, 0, 0]\n",
    "            max_inc_para = [\"\", \"\", \"\", \"\", \"\"]\n",
    "            tot_neg_inc = 0\n",
    "            tot_neu_inc = 0\n",
    "            tot_pos_inc = 0\n",
    "            tot_noff_inc = 0\n",
    "            tot_off_inc = 0\n",
    "            \n",
    "            for p in paraphrases:\n",
    "                p_string = re.sub(r'_', ' ', p[0]) # the underscores are removed for sentiment computation - experiment?\n",
    "                q_string = re.sub(r'_', ' ', q)\n",
    "                \n",
    "                if (q_string in p_string):\n",
    "                    # print(\"Paraphrase is superstring, skipping!\")\n",
    "                    # print()\n",
    "                    continue\n",
    "                    \n",
    "                # replacement\n",
    "                pattern = re.compile(r'\\b'+q_string+r'\\b', re.IGNORECASE)\n",
    "                new_sentence = pattern.sub(p_string, text)\n",
    "                # at this point, we could check the integrity of the paraphrase\n",
    "\n",
    "                # get the sentiment/offensive scores for this paraphrase\n",
    "                scores = list(self.get_sentiment(new_sentence, sentiment_pack))\n",
    "                scores = scores + list(self.get_sentiment(new_sentence, offensive_pack))\n",
    "\n",
    "                # update the quality phrase's sentiment statistics with the sentiment shifts from this paraphrase\n",
    "                shifts = [0, 0, 0, 0, 0]\n",
    "                for i in range(0, len(scores)):\n",
    "                    shifts[i] = scores[i] - orig_scores[i]\n",
    "                    sentiment_shift[i] += shifts[i]\n",
    "                    if (shifts[i] > max_inc[i]):\n",
    "                        max_inc[i] = shifts[i]\n",
    "                        max_inc_para[i] = p_string\n",
    "\n",
    "                # update the relevant scores for detection\n",
    "                if (shifts[0] > 0):\n",
    "                    tot_neg_inc += shifts[0]\n",
    "                if (shifts[1] > 0):\n",
    "                    tot_neu_inc += shifts[1]\n",
    "                if (shifts[2] > 0):\n",
    "                    tot_pos_inc += shifts[2]\n",
    "                if (shifts[3] > 0):\n",
    "                    tot_noff_inc += shifts[3]\n",
    "                if (shifts[4] > 0):\n",
    "                    tot_off_inc += shifts[4]\n",
    "                \n",
    "                # print(p_string)\n",
    "                # print(shifts)\n",
    "\n",
    "            for val in sentiment_shift:\n",
    "                val /= num_paraphrases\n",
    "            if (show_stats == True):\n",
    "                print(\"AVERAGE SENTIMENT SHIFTS: {}\".format(sentiment_shift))\n",
    "                print(\"MAX INCREASE FROM A PHRASE: {}\".format(max_inc))\n",
    "                print(\"PHRASES THAT CAUSED EACH ^: {}\".format(max_inc_para))\n",
    "                print(\"TOTAL NEGATIVE INCREASE: {}\".format(tot_neg_inc))\n",
    "                print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_neu_inc))\n",
    "                print(\"TOTAL POSITIVE INCREASE: {}\".format(tot_pos_inc))\n",
    "                print(\"TOTAL NON-OFFENSIVE INCREASE: {}\".format(tot_noff_inc))\n",
    "                print(\"TOTAL OFFENSIVE INCREASE: {}\".format(tot_off_inc))\n",
    "\n",
    "            score = tot_neg_inc + tot_neu_inc + 2*(tot_noff_inc + tot_off_inc)\n",
    "            phrase_scores.append((q_string, score))\n",
    "\n",
    "        phrase_scores = list(sorted(phrase_scores, key=lambda x: x[1], reverse=True))\n",
    "        return phrase_scores\n",
    "    \n",
    "    def detect_euphs(self, s, topic_threshold, num_paraphrases, show_stats=False):\n",
    "        s = self.preprocess(s)\n",
    "        print(s)\n",
    "\n",
    "        bigrammed_phrases = self.bigram_phraser[s.split()]\n",
    "        trigrammed_phrases = self.trigram_phraser[bigrammed_phrases]\n",
    "        print(\"\\nDETECTED PHRASES: {}\".format(trigrammed_phrases))\n",
    "\n",
    "        data = []\n",
    "        data.append(trigrammed_phrases)\n",
    "        # train model on input data\n",
    "        self.model.train(data, total_examples=len(data), epochs=10)\n",
    "\n",
    "        quality_phrases = self.topically_filter_phrases(trigrammed_phrases, self.topic_list, self.stopwords, topic_threshold, show_stats)\n",
    "        print(\"\\nRELEVANT PHRASES: {}\".format(quality_phrases))\n",
    "\n",
    "        candidate_list = self.get_top_euph_candidates(s, quality_phrases, num_paraphrases, \n",
    "                                            self.model, self.sentiment_pack, self.offensive_pack, \n",
    "                                            show_stats)\n",
    "        \n",
    "        self.model = self.base_model # reset\n",
    "        \n",
    "        return candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6dd55a-0ba9-450b-8b83-994b81156ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup took 76.65264558792114 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "euph_detector = Euph_Detection('data/bigram_phraser_7', 'data/trigram_phraser_7', \n",
    "                               'data/wv_model_7', 'data/stopwords.txt', \n",
    "                               'sentiment', 'offensive')\n",
    "print(\"Setup took {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce303206-46ad-453d-8e81-8af62e74caa1",
   "metadata": {},
   "source": [
    "#### Input your sentence below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff95dfd0-9994-44ac-8d11-3f9bba425f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she was happy to announce to her parents that they would soon be grandparents as she had a bun in the oven\n",
      "\n",
      "DETECTED PHRASES: ['she_was', 'happy_to_announce', 'to', 'her_parents', 'that', 'they', 'would_soon', 'be', 'grandparents', 'as', 'she_had', 'a', 'bun_in_the_oven']\n",
      "\n",
      "RELEVANT PHRASES: ['she_was', 'her_parents', 'grandparents', 'she_had', 'bun_in_the_oven']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:14<00:00,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EUPH CANDIDATE RANKING: [('bun in the oven', 6.281971137272194), ('she had', 2.188295707805082), ('grandparents', 1.6664501605555415), ('she was', 1.621023417916149), ('her parents', 1.4890306764282286)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = \"She was happy to announce to her parents that they would soon be grandparents as she had a bun in the oven\"\n",
    "candidate_ranking = euph_detector.detect_euphs(s, topic_threshold=1.45, num_paraphrases=25, show_stats=False)\n",
    "\n",
    "print(\"\\nEUPH CANDIDATE RANKING: {}\".format(candidate_ranking))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7a913-ad6c-4dff-97ef-16d99de62021",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyzing the Process\n",
    "After running Euph_Detection on a sentence, you can further look at the intermediate outputs for a specific candidate phrase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680ebea-a5bc-4c71-bc40-4d6a3a266048",
   "metadata": {},
   "source": [
    "#### Topic Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c992752-906b-4a98-9a6b-41b29f00b845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics: 0.03169498220086098\n",
      "death: 0.23297420144081116\n",
      "kill: 0.0050100162625312805\n",
      "crime: -0.008931629359722137\n",
      "drugs: 0.12348905205726624\n",
      "alcohol: 0.0824684277176857\n",
      "fat: 0.10275810211896896\n",
      "old: 0.24060304462909698\n",
      "poor: 0.2921329736709595\n",
      "cheap: 0.009934276342391968\n",
      "sex: 0.20923519134521484\n",
      "sexual: 0.08769768476486206\n",
      "employment: 0.04461533948779106\n",
      "job: 0.13673429191112518\n",
      "disability: 0.3075178265571594\n",
      "disabled: 0.3100000321865082\n",
      "accident: 0.16150902211666107\n",
      "pregnant: 0.3779146671295166\n",
      "poop: 0.12431168556213379\n",
      "sickness: 0.24127842485904694\n",
      "race: 0.10285885632038116\n",
      "racial: 0.04492925852537155\n",
      "vomit: -0.023195646703243256\n",
      "SIMILAR TOPICS: ['poor', 'disability', 'disabled', 'pregnant']\n",
      "TOTAL SCORE: 3.2696673572063446\n"
     ]
    }
   ],
   "source": [
    "test_phrase = 'grandparents'\n",
    "similar_topics = []\n",
    "\n",
    "topic_list = euph_detector.topic_list\n",
    "model = euph_detector.model\n",
    "\n",
    "score = 0\n",
    "for topic in topic_list:\n",
    "    similarity = model.wv.similarity(test_phrase, topic)\n",
    "    if (similarity > 0.25):\n",
    "        similar_topics.append(topic)\n",
    "    if (similarity > 0):\n",
    "        score += similarity\n",
    "    print('{}: {}'.format(topic, similarity))\n",
    "\n",
    "print('SIMILAR TOPICS: {}'.format(similar_topics))\n",
    "print('TOTAL SCORE: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727aec8-f2a7-484d-a9cc-c31ca8634b58",
   "metadata": {},
   "source": [
    "#### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf9c28-1d80-4617-b957-0a7ebe01f0d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT OF ORIGINAL SENTENCE: [0.0018395717, 0.05148052, 0.94667983, 0.80990493, 0.19009507]\n",
      "\n",
      "grandparents\n",
      "aunts and uncles\n",
      "[0.0004102575, 0.018325869, -0.018736005, -0.09982771, 0.09982771]\n",
      "\n",
      "grandchildren\n",
      "[-0.0003691659, -0.011124246, 0.011493623, 0.01240021, -0.012400284]\n",
      "\n",
      "siblings\n",
      "[-0.0004157899, 0.005893085, -0.005477071, 0.0139247775, -0.013924703]\n",
      "\n",
      "in-laws\n",
      "[-0.00029044622, 0.006497167, -0.0062065125, -0.024477601, 0.024477646]\n",
      "\n",
      "relatives\n",
      "[0.00069687364, 0.024621267, -0.025318086, -0.006095648, 0.006095752]\n",
      "\n",
      "other relatives\n",
      "[0.00077235873, 0.02984209, -0.030614376, 0.0038375854, -0.00383766]\n",
      "\n",
      "nephews\n",
      "[-0.00034243532, 0.0064492896, -0.0061067343, 0.002517581, -0.0025176853]\n",
      "\n",
      "great-grandparents\n",
      "Paraphrase is superstring, skipping!\n",
      "\n",
      "older siblings\n",
      "[-0.00023880275, 0.0111381, -0.010899305, -0.0011742115, 0.0011741668]\n",
      "\n",
      "grandkids\n",
      "[-0.00047420408, -0.008419838, 0.008894205, -0.012013733, 0.0120137185]\n",
      "\n",
      "adult children\n",
      "[0.0030467235, 0.059609625, -0.0626564, -0.10941303, 0.10941309]\n",
      "\n",
      "their grandparents\n",
      "Paraphrase is superstring, skipping!\n",
      "\n",
      "mom and dad\n",
      "[-0.00059583294, -0.008399241, 0.008995175, -0.0007426739, 0.000742659]\n",
      "\n",
      "extended family\n",
      "[-0.0004405746, -0.0035314, 0.003971994, 0.011281967, -0.011281922]\n",
      "\n",
      "family members\n",
      "[-0.00031721767, 0.0025665313, -0.0022491813, 0.008739114, -0.008739114]\n",
      "\n",
      "their grandchildren\n",
      "[-0.0001400559, -0.0031048171, 0.003244996, 0.01605159, -0.016051486]\n",
      "\n",
      "biological parents\n",
      "[0.00018340524, 0.022374053, -0.022557318, -0.03864956, 0.038649634]\n",
      "\n",
      "adoptees\n",
      "[-0.0005410821, -0.0077806003, 0.008321881, 0.026791751, -0.026791707]\n",
      "\n",
      "daughters\n",
      "[-5.975424e-05, 0.011700075, -0.011640191, -0.02121222, 0.02121222]\n",
      "\n",
      "parents\n",
      "[0.0001235205, 0.009710282, -0.009833753, -0.028059483, 0.028059423]\n",
      "\n",
      "uncles\n",
      "[0.0003804335, 0.01868331, -0.01906383, -0.043486, 0.04348606]\n",
      "\n",
      "teenage children\n",
      "[0.0076140184, 0.11450291, -0.12211698, -0.10829276, 0.10829288]\n",
      "\n",
      "birth parents\n",
      "[0.000121170306, 0.019860733, -0.019981742, -0.01912129, 0.019121185]\n",
      "\n",
      "nieces and nephews\n",
      "[-0.0005050752, -0.0033206157, 0.0038257241, 0.0021170378, -0.0021170974]\n",
      "\n",
      "younger siblings\n",
      "[-0.0003537516, 0.0068355054, -0.006481588, -0.0006285906, 0.0006285757]\n",
      "\n",
      "AVERAGE SENTIMENT SHIFTS: [0.008264572941698134, 0.32292913272976875, -0.3311914801597595, -0.4155328869819641, 0.41553305089473724]\n",
      "MAX INCREASE FROM A PHRASE: [0.0076140184, 0.11450291, 0.011493623, 0.026791751, 0.10941309]\n",
      "PHRASES THAT CAUSED EACH ^: ['teenage children', 'teenage children', 'grandchildren', 'adoptees', 'adult children']\n",
      "TOTAL NEGATIVE INCREASE: 0.013348761363886297\n",
      "TOTAL NEUTRAL INCREASE: 0.36860989034175873\n",
      "TOTAL POSITIVE INCREASE: 0.04874759912490845\n",
      "TOTAL NON-OFFENSIVE INCREASE: 0.09766161441802979\n",
      "TOTAL OFFENSIVE INCREASE: 0.5131947100162506\n",
      "('grandparents', 0.6108563244342804)\n"
     ]
    }
   ],
   "source": [
    "text = s\n",
    "q = 'grandparents'\n",
    "\n",
    "sentiment_pack = euph_detector.sentiment_pack\n",
    "offensive_pack = euph_detector.offensive_pack\n",
    "model = euph_detector.model\n",
    "\n",
    "orig_scores = list(euph_detector.get_sentiment(s, sentiment_pack))\n",
    "orig_scores = orig_scores + list(euph_detector.get_sentiment(text, offensive_pack))\n",
    "print('SENTIMENT OF ORIGINAL SENTENCE: {}'.format(orig_scores))\n",
    "\n",
    "num_paraphrases=25\n",
    "paraphrases = []\n",
    "print('\\n'+q)\n",
    "paraphrases = model.wv.most_similar(q, topn = num_paraphrases) # can swap out\n",
    "\n",
    "# various sentiment statistics\n",
    "sentiment_shift = [0, 0, 0, 0, 0] # [neg, neu, pos, off, n-off]\n",
    "max_inc = [0, 0, 0, 0, 0]\n",
    "max_inc_para = [\"\", \"\", \"\", \"\", \"\"]\n",
    "tot_neg_inc = 0\n",
    "tot_neu_inc = 0\n",
    "tot_pos_inc = 0\n",
    "tot_noff_inc = 0\n",
    "tot_off_inc = 0\n",
    "\n",
    "for p in paraphrases:\n",
    "    p_string = re.sub(r'_', ' ', p[0]) # the underscores are removed for sentiment computation - experiment?\n",
    "    q_string = re.sub(r'_', ' ', q) # string for the original phrase\n",
    "    \n",
    "    # sentences_a = [p_string]\n",
    "    # sentences_b = [q_string]\n",
    "    # similarities = simcse_model.similarity(sentences_a, sentences_b)\n",
    "    # if (similarities < 0.7):\n",
    "    #     print(p_string + \" is being skipped.\")\n",
    "    #     continue\n",
    "    print(p_string)\n",
    "    # cos_sim = get_phrase_cos_sim(p_string, q_string)\n",
    "    if (q_string in p_string):\n",
    "        print(\"Paraphrase is superstring, skipping!\")\n",
    "        print()\n",
    "        continue\n",
    "\n",
    "    # replacement\n",
    "    pattern = re.compile(r'\\b'+q_string+r'\\b', re.IGNORECASE)\n",
    "    new_sentence = pattern.sub(p_string, text)\n",
    "    \n",
    "    # at this point, we could check the integrity of the paraphrase\n",
    "\n",
    "    # get the sentiment/offensive scores for this paraphrase\n",
    "    scores = list(euph_detector.get_sentiment(new_sentence, sentiment_pack))\n",
    "    scores = scores + list(euph_detector.get_sentiment(new_sentence, offensive_pack))\n",
    "\n",
    "    # update the quality phrase's sentiment statistics with the sentiment shifts from this paraphrase\n",
    "    shifts = [0, 0, 0, 0, 0]\n",
    "    for i in range(0, len(scores)):\n",
    "        shifts[i] = scores[i] - orig_scores[i]\n",
    "        sentiment_shift[i] += shifts[i]\n",
    "        if (shifts[i] > max_inc[i]):\n",
    "            max_inc[i] = shifts[i]\n",
    "            max_inc_para[i] = p_string\n",
    "    print(shifts)\n",
    "    \n",
    "    print()\n",
    "    # update the relevant scores for detection\n",
    "    if (shifts[0] > 0):\n",
    "        tot_neg_inc += shifts[0]\n",
    "    if (shifts[1] > 0):\n",
    "        tot_neu_inc += shifts[1]\n",
    "    if (shifts[2] > 0):\n",
    "        tot_pos_inc += shifts[2]\n",
    "    if (shifts[3] > 0):\n",
    "        tot_noff_inc += shifts[3]\n",
    "    if (shifts[4] > 0):\n",
    "        tot_off_inc += shifts[4]     \n",
    "\n",
    "    for val in sentiment_shift:\n",
    "        val /= num_paraphrases\n",
    "    \n",
    "print(\"AVERAGE SENTIMENT SHIFTS: {}\".format(sentiment_shift))\n",
    "print(\"MAX INCREASE FROM A PHRASE: {}\".format(max_inc))\n",
    "print(\"PHRASES THAT CAUSED EACH ^: {}\".format(max_inc_para))\n",
    "print(\"TOTAL NEGATIVE INCREASE: {}\".format(tot_neg_inc))\n",
    "print(\"TOTAL NEUTRAL INCREASE: {}\".format(tot_neu_inc))\n",
    "print(\"TOTAL POSITIVE INCREASE: {}\".format(tot_pos_inc))\n",
    "print(\"TOTAL NON-OFFENSIVE INCREASE: {}\".format(tot_noff_inc))\n",
    "print(\"TOTAL OFFENSIVE INCREASE: {}\".format(tot_off_inc))\n",
    "\n",
    "# score = 0.5*tot_neg_inc + 0.25*tot_neu_inc + 1.5*tot_off_inc\n",
    "# score = tot_neg_inc + tot_neu_inc + tot_pos_inc + 3*(tot_noff_inc + tot_off_inc)\n",
    "score = tot_noff_inc + tot_off_inc\n",
    "# score = tot_neg_inc + tot_neu_inc + (tot_off_inc * 2)\n",
    "print((q_string, score))\n",
    "# print((q_string, sentiment_shift[0]+sentiment_shift[1]+sentiment_shift[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e8b13e-618d-4089-b942-30c3e9a75eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
